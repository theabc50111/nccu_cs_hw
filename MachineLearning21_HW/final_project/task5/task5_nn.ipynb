{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21831/1371881661.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 03:06:10.074229: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 03:06:11.156848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.157336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.161435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.161882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.162317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.162755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.002572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.011186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.011629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.016183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.016616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.017051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 9648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-21 03:06:15.040121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.040529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 9648 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "time: 16.6 s (started: 2021-12-21 03:05:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "train_df = pd.read_csv('task3_2021.training.csv')\n",
    "test_df = pd.read_csv('task3_2021.test.csv')\n",
    "n_pre_train_y = train_df['target']\n",
    "n_pre_train_x = train_df.drop(['target'], axis=1)\n",
    "n_pre_test_x = test_df\n",
    "# display(n_pre_train_x.head(), n_pre_train_y.head(), n_pre_train_y.nunique(), n_pre_test_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 126 ms (started: 2021-12-21 03:06:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def oh_pre(x):\n",
    "    for k in ['f15', 'f16', 'f17']:\n",
    "        tmp_one_hot_k =  pd.get_dummies(x[k], prefix=f\"{k}\")\n",
    "        x = pd.concat([x, tmp_one_hot_k],axis=1)\n",
    "        x = x.drop([k], axis=1)\n",
    "    return x\n",
    "\n",
    "oh_pre_train_x = oh_pre(n_pre_train_x)\n",
    "oh_pre_test_x = oh_pre(n_pre_test_x)\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(oh_pre_train_x)\n",
    "test_x = scaler.transform(oh_pre_test_x)\n",
    "\n",
    "ohenc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "train_y = ohenc.fit_transform(n_pre_train_y.values.reshape(-1,1))\n",
    "# mse = make_scorer(mean_squared_error, squared=False)nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 2.2508 - accuracy: 0.1523 - val_loss: 2.0585 - val_accuracy: 0.2120\n",
      "Epoch 2/5000\n",
      "180/180 [==============================] - 0s 918us/step - loss: 1.8423 - accuracy: 0.2764 - val_loss: 1.6360 - val_accuracy: 0.3390\n",
      "Epoch 3/5000\n",
      "180/180 [==============================] - 0s 918us/step - loss: 1.4547 - accuracy: 0.4071 - val_loss: 1.3031 - val_accuracy: 0.4620\n",
      "Epoch 4/5000\n",
      "180/180 [==============================] - 0s 904us/step - loss: 1.1683 - accuracy: 0.5481 - val_loss: 1.0642 - val_accuracy: 0.5980\n",
      "Epoch 5/5000\n",
      "180/180 [==============================] - 0s 923us/step - loss: 0.9627 - accuracy: 0.6586 - val_loss: 0.8832 - val_accuracy: 0.6710\n",
      "Epoch 6/5000\n",
      "180/180 [==============================] - 0s 916us/step - loss: 0.8133 - accuracy: 0.7289 - val_loss: 0.7567 - val_accuracy: 0.7450\n",
      "Epoch 7/5000\n",
      "180/180 [==============================] - 0s 895us/step - loss: 0.7010 - accuracy: 0.7751 - val_loss: 0.6582 - val_accuracy: 0.7960\n",
      "Epoch 8/5000\n",
      "180/180 [==============================] - 0s 946us/step - loss: 0.6136 - accuracy: 0.8071 - val_loss: 0.5849 - val_accuracy: 0.8060\n",
      "Epoch 9/5000\n",
      "180/180 [==============================] - 0s 937us/step - loss: 0.5433 - accuracy: 0.8300 - val_loss: 0.5232 - val_accuracy: 0.8360\n",
      "Epoch 10/5000\n",
      "180/180 [==============================] - 0s 883us/step - loss: 0.4910 - accuracy: 0.8469 - val_loss: 0.4716 - val_accuracy: 0.8570\n",
      "Epoch 11/5000\n",
      "180/180 [==============================] - 0s 941us/step - loss: 0.4441 - accuracy: 0.8607 - val_loss: 0.4339 - val_accuracy: 0.8680\n",
      "Epoch 12/5000\n",
      "180/180 [==============================] - 0s 903us/step - loss: 0.4089 - accuracy: 0.8698 - val_loss: 0.3961 - val_accuracy: 0.8850\n",
      "Epoch 13/5000\n",
      "180/180 [==============================] - 0s 902us/step - loss: 0.3776 - accuracy: 0.8812 - val_loss: 0.3761 - val_accuracy: 0.8770\n",
      "Epoch 14/5000\n",
      "180/180 [==============================] - 0s 920us/step - loss: 0.3528 - accuracy: 0.8878 - val_loss: 0.3520 - val_accuracy: 0.8940\n",
      "Epoch 15/5000\n",
      "180/180 [==============================] - 0s 912us/step - loss: 0.3318 - accuracy: 0.8899 - val_loss: 0.3285 - val_accuracy: 0.8960\n",
      "Epoch 16/5000\n",
      "180/180 [==============================] - 0s 890us/step - loss: 0.3145 - accuracy: 0.8984 - val_loss: 0.3131 - val_accuracy: 0.8850\n",
      "Epoch 17/5000\n",
      "180/180 [==============================] - 0s 916us/step - loss: 0.3008 - accuracy: 0.8979 - val_loss: 0.2974 - val_accuracy: 0.9090\n",
      "Epoch 18/5000\n",
      "180/180 [==============================] - 0s 936us/step - loss: 0.2872 - accuracy: 0.9029 - val_loss: 0.2893 - val_accuracy: 0.9010\n",
      "Epoch 19/5000\n",
      "180/180 [==============================] - 0s 926us/step - loss: 0.2770 - accuracy: 0.9036 - val_loss: 0.2780 - val_accuracy: 0.9000\n",
      "Epoch 20/5000\n",
      "180/180 [==============================] - 0s 936us/step - loss: 0.2677 - accuracy: 0.9079 - val_loss: 0.2665 - val_accuracy: 0.9060\n",
      "Epoch 21/5000\n",
      "180/180 [==============================] - 0s 904us/step - loss: 0.2585 - accuracy: 0.9102 - val_loss: 0.2782 - val_accuracy: 0.8990\n",
      "Epoch 22/5000\n",
      "180/180 [==============================] - 0s 934us/step - loss: 0.2518 - accuracy: 0.9109 - val_loss: 0.2587 - val_accuracy: 0.9090\n",
      "Epoch 23/5000\n",
      "180/180 [==============================] - 0s 888us/step - loss: 0.2451 - accuracy: 0.9119 - val_loss: 0.2542 - val_accuracy: 0.9060\n",
      "Epoch 24/5000\n",
      "180/180 [==============================] - 0s 896us/step - loss: 0.2403 - accuracy: 0.9142 - val_loss: 0.2475 - val_accuracy: 0.9090\n",
      "Epoch 25/5000\n",
      "180/180 [==============================] - 0s 928us/step - loss: 0.2346 - accuracy: 0.9180 - val_loss: 0.2420 - val_accuracy: 0.9060\n",
      "Epoch 26/5000\n",
      "180/180 [==============================] - 0s 930us/step - loss: 0.2305 - accuracy: 0.9160 - val_loss: 0.2443 - val_accuracy: 0.9030\n",
      "Epoch 27/5000\n",
      "180/180 [==============================] - 0s 956us/step - loss: 0.2266 - accuracy: 0.9187 - val_loss: 0.2402 - val_accuracy: 0.9100\n",
      "Epoch 28/5000\n",
      "180/180 [==============================] - 0s 928us/step - loss: 0.2224 - accuracy: 0.9187 - val_loss: 0.2326 - val_accuracy: 0.9100\n",
      "Epoch 29/5000\n",
      "180/180 [==============================] - 0s 889us/step - loss: 0.2184 - accuracy: 0.9210 - val_loss: 0.2379 - val_accuracy: 0.9060\n",
      "Epoch 30/5000\n",
      "180/180 [==============================] - 0s 891us/step - loss: 0.2152 - accuracy: 0.9207 - val_loss: 0.2216 - val_accuracy: 0.9200\n",
      "Epoch 31/5000\n",
      "180/180 [==============================] - 0s 888us/step - loss: 0.2132 - accuracy: 0.9222 - val_loss: 0.2207 - val_accuracy: 0.9190\n",
      "Epoch 32/5000\n",
      "180/180 [==============================] - 0s 884us/step - loss: 0.2079 - accuracy: 0.9237 - val_loss: 0.2220 - val_accuracy: 0.9150\n",
      "Epoch 33/5000\n",
      "180/180 [==============================] - 0s 909us/step - loss: 0.2076 - accuracy: 0.9213 - val_loss: 0.2158 - val_accuracy: 0.9170\n",
      "Epoch 34/5000\n",
      "180/180 [==============================] - 0s 914us/step - loss: 0.2054 - accuracy: 0.9228 - val_loss: 0.2130 - val_accuracy: 0.9210\n",
      "Epoch 35/5000\n",
      "180/180 [==============================] - 0s 892us/step - loss: 0.2010 - accuracy: 0.9276 - val_loss: 0.2158 - val_accuracy: 0.9190\n",
      "Epoch 36/5000\n",
      "180/180 [==============================] - 0s 898us/step - loss: 0.2020 - accuracy: 0.9249 - val_loss: 0.2067 - val_accuracy: 0.9260\n",
      "Epoch 37/5000\n",
      "180/180 [==============================] - 0s 898us/step - loss: 0.1967 - accuracy: 0.9273 - val_loss: 0.2100 - val_accuracy: 0.9190\n",
      "Epoch 38/5000\n",
      "180/180 [==============================] - 0s 896us/step - loss: 0.1968 - accuracy: 0.9261 - val_loss: 0.2218 - val_accuracy: 0.9120\n",
      "Epoch 39/5000\n",
      "180/180 [==============================] - 0s 909us/step - loss: 0.1944 - accuracy: 0.9283 - val_loss: 0.2099 - val_accuracy: 0.9170\n",
      "Epoch 40/5000\n",
      "180/180 [==============================] - 0s 911us/step - loss: 0.1927 - accuracy: 0.9273 - val_loss: 0.2104 - val_accuracy: 0.9160\n",
      "Epoch 41/5000\n",
      "180/180 [==============================] - 0s 926us/step - loss: 0.1905 - accuracy: 0.9271 - val_loss: 0.2041 - val_accuracy: 0.9230\n",
      "Epoch 42/5000\n",
      "180/180 [==============================] - 0s 927us/step - loss: 0.1895 - accuracy: 0.9259 - val_loss: 0.2093 - val_accuracy: 0.9130\n",
      "Epoch 43/5000\n",
      "180/180 [==============================] - 0s 900us/step - loss: 0.1858 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9220\n",
      "Epoch 44/5000\n",
      "180/180 [==============================] - 0s 894us/step - loss: 0.1878 - accuracy: 0.9273 - val_loss: 0.2030 - val_accuracy: 0.9250\n",
      "Epoch 45/5000\n",
      "180/180 [==============================] - 0s 910us/step - loss: 0.1850 - accuracy: 0.9293 - val_loss: 0.2010 - val_accuracy: 0.9230\n",
      "Epoch 46/5000\n",
      "180/180 [==============================] - 0s 930us/step - loss: 0.1840 - accuracy: 0.9292 - val_loss: 0.1941 - val_accuracy: 0.9280\n",
      "Epoch 47/5000\n",
      "180/180 [==============================] - 0s 927us/step - loss: 0.1830 - accuracy: 0.9302 - val_loss: 0.2020 - val_accuracy: 0.9220\n",
      "Epoch 48/5000\n",
      "180/180 [==============================] - 0s 895us/step - loss: 0.1819 - accuracy: 0.9304 - val_loss: 0.1955 - val_accuracy: 0.9240\n",
      "Epoch 49/5000\n",
      "180/180 [==============================] - 0s 903us/step - loss: 0.1802 - accuracy: 0.9316 - val_loss: 0.2050 - val_accuracy: 0.9200\n",
      "Epoch 50/5000\n",
      "180/180 [==============================] - 0s 890us/step - loss: 0.1796 - accuracy: 0.9317 - val_loss: 0.1963 - val_accuracy: 0.9320\n",
      "Epoch 51/5000\n",
      "180/180 [==============================] - 0s 894us/step - loss: 0.1773 - accuracy: 0.9322 - val_loss: 0.1958 - val_accuracy: 0.9260\n",
      "Epoch 52/5000\n",
      "180/180 [==============================] - 0s 889us/step - loss: 0.1787 - accuracy: 0.9319 - val_loss: 0.1957 - val_accuracy: 0.9190\n",
      "Epoch 53/5000\n",
      "180/180 [==============================] - 0s 906us/step - loss: 0.1758 - accuracy: 0.9339 - val_loss: 0.1966 - val_accuracy: 0.9260\n",
      "Epoch 54/5000\n",
      "180/180 [==============================] - 0s 901us/step - loss: 0.1746 - accuracy: 0.9343 - val_loss: 0.1961 - val_accuracy: 0.9250\n",
      "Epoch 55/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1746 - accuracy: 0.9334 - val_loss: 0.1908 - val_accuracy: 0.9270\n",
      "Epoch 56/5000\n",
      "180/180 [==============================] - 0s 897us/step - loss: 0.1744 - accuracy: 0.9331 - val_loss: 0.1968 - val_accuracy: 0.9290\n",
      "Epoch 57/5000\n",
      "180/180 [==============================] - 0s 913us/step - loss: 0.1737 - accuracy: 0.9334 - val_loss: 0.1923 - val_accuracy: 0.9240\n",
      "Epoch 58/5000\n",
      "180/180 [==============================] - 0s 909us/step - loss: 0.1718 - accuracy: 0.9308 - val_loss: 0.2014 - val_accuracy: 0.9230\n",
      "Epoch 59/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1716 - accuracy: 0.9318 - val_loss: 0.1891 - val_accuracy: 0.9330\n",
      "Epoch 60/5000\n",
      "180/180 [==============================] - 0s 900us/step - loss: 0.1697 - accuracy: 0.9351 - val_loss: 0.1945 - val_accuracy: 0.9200\n",
      "Epoch 61/5000\n",
      "180/180 [==============================] - 0s 917us/step - loss: 0.1686 - accuracy: 0.9369 - val_loss: 0.1906 - val_accuracy: 0.9250\n",
      "Epoch 62/5000\n",
      "180/180 [==============================] - 0s 899us/step - loss: 0.1686 - accuracy: 0.9323 - val_loss: 0.1943 - val_accuracy: 0.9230\n",
      "Epoch 63/5000\n",
      "180/180 [==============================] - 0s 917us/step - loss: 0.1681 - accuracy: 0.9334 - val_loss: 0.2036 - val_accuracy: 0.9200\n",
      "Epoch 64/5000\n",
      "180/180 [==============================] - 0s 924us/step - loss: 0.1673 - accuracy: 0.9358 - val_loss: 0.1879 - val_accuracy: 0.9300\n",
      "Epoch 65/5000\n",
      "180/180 [==============================] - 0s 910us/step - loss: 0.1668 - accuracy: 0.9348 - val_loss: 0.2001 - val_accuracy: 0.9190\n",
      "Epoch 66/5000\n",
      "180/180 [==============================] - 0s 896us/step - loss: 0.1645 - accuracy: 0.9378 - val_loss: 0.1912 - val_accuracy: 0.9250\n",
      "Epoch 67/5000\n",
      "180/180 [==============================] - 0s 881us/step - loss: 0.1662 - accuracy: 0.9360 - val_loss: 0.1880 - val_accuracy: 0.9240\n",
      "Epoch 68/5000\n",
      "180/180 [==============================] - 0s 903us/step - loss: 0.1671 - accuracy: 0.9354 - val_loss: 0.1923 - val_accuracy: 0.9260\n",
      "Epoch 69/5000\n",
      "180/180 [==============================] - 0s 910us/step - loss: 0.1641 - accuracy: 0.9362 - val_loss: 0.1916 - val_accuracy: 0.9250\n",
      "Epoch 70/5000\n",
      "180/180 [==============================] - 0s 910us/step - loss: 0.1639 - accuracy: 0.9351 - val_loss: 0.1894 - val_accuracy: 0.9270\n",
      "Epoch 71/5000\n",
      "180/180 [==============================] - 0s 901us/step - loss: 0.1635 - accuracy: 0.9379 - val_loss: 0.1959 - val_accuracy: 0.9240\n",
      "Epoch 72/5000\n",
      "180/180 [==============================] - 0s 888us/step - loss: 0.1611 - accuracy: 0.9393 - val_loss: 0.1951 - val_accuracy: 0.9260\n",
      "Epoch 73/5000\n",
      "180/180 [==============================] - 0s 892us/step - loss: 0.1607 - accuracy: 0.9364 - val_loss: 0.1969 - val_accuracy: 0.9200\n",
      "Epoch 74/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1616 - accuracy: 0.9400 - val_loss: 0.1889 - val_accuracy: 0.9290\n",
      "Epoch 75/5000\n",
      "180/180 [==============================] - 0s 910us/step - loss: 0.1616 - accuracy: 0.9359 - val_loss: 0.1913 - val_accuracy: 0.9270\n",
      "Epoch 76/5000\n",
      "180/180 [==============================] - 0s 913us/step - loss: 0.1603 - accuracy: 0.9388 - val_loss: 0.1948 - val_accuracy: 0.9190\n",
      "Epoch 77/5000\n",
      "180/180 [==============================] - 0s 921us/step - loss: 0.1617 - accuracy: 0.9361 - val_loss: 0.1959 - val_accuracy: 0.9240\n",
      "Epoch 78/5000\n",
      "180/180 [==============================] - 0s 890us/step - loss: 0.1601 - accuracy: 0.9376 - val_loss: 0.1961 - val_accuracy: 0.9280\n",
      "Epoch 79/5000\n",
      "180/180 [==============================] - 0s 901us/step - loss: 0.1582 - accuracy: 0.9393 - val_loss: 0.1966 - val_accuracy: 0.9270\n",
      "Epoch 80/5000\n",
      "180/180 [==============================] - 0s 919us/step - loss: 0.1576 - accuracy: 0.9373 - val_loss: 0.1909 - val_accuracy: 0.9210\n",
      "Epoch 81/5000\n",
      "180/180 [==============================] - 0s 912us/step - loss: 0.1603 - accuracy: 0.9369 - val_loss: 0.1848 - val_accuracy: 0.9280\n",
      "Epoch 82/5000\n",
      "180/180 [==============================] - 0s 878us/step - loss: 0.1558 - accuracy: 0.9381 - val_loss: 0.1939 - val_accuracy: 0.9250\n",
      "Epoch 83/5000\n",
      "180/180 [==============================] - 0s 895us/step - loss: 0.1578 - accuracy: 0.9390 - val_loss: 0.1809 - val_accuracy: 0.9360\n",
      "Epoch 84/5000\n",
      "180/180 [==============================] - 0s 907us/step - loss: 0.1548 - accuracy: 0.9396 - val_loss: 0.1866 - val_accuracy: 0.9270\n",
      "Epoch 85/5000\n",
      "180/180 [==============================] - 0s 903us/step - loss: 0.1574 - accuracy: 0.9380 - val_loss: 0.1892 - val_accuracy: 0.9260\n",
      "Epoch 86/5000\n",
      "180/180 [==============================] - 0s 895us/step - loss: 0.1558 - accuracy: 0.9402 - val_loss: 0.2011 - val_accuracy: 0.9220\n",
      "Epoch 87/5000\n",
      "180/180 [==============================] - 0s 881us/step - loss: 0.1561 - accuracy: 0.9416 - val_loss: 0.1942 - val_accuracy: 0.9270\n",
      "Epoch 88/5000\n",
      "180/180 [==============================] - 0s 943us/step - loss: 0.1538 - accuracy: 0.9394 - val_loss: 0.1996 - val_accuracy: 0.9240\n",
      "Epoch 89/5000\n",
      "180/180 [==============================] - 0s 929us/step - loss: 0.1520 - accuracy: 0.9413 - val_loss: 0.2005 - val_accuracy: 0.9190\n",
      "Epoch 90/5000\n",
      "180/180 [==============================] - 0s 927us/step - loss: 0.1549 - accuracy: 0.9406 - val_loss: 0.1914 - val_accuracy: 0.9270\n",
      "Epoch 91/5000\n",
      "180/180 [==============================] - 0s 892us/step - loss: 0.1558 - accuracy: 0.9383 - val_loss: 0.1926 - val_accuracy: 0.9280\n",
      "Epoch 92/5000\n",
      "180/180 [==============================] - 0s 932us/step - loss: 0.1526 - accuracy: 0.9392 - val_loss: 0.1904 - val_accuracy: 0.9200\n",
      "Epoch 93/5000\n",
      "180/180 [==============================] - 0s 889us/step - loss: 0.1528 - accuracy: 0.9416 - val_loss: 0.1883 - val_accuracy: 0.9290\n",
      "Epoch 94/5000\n",
      "180/180 [==============================] - 0s 906us/step - loss: 0.1507 - accuracy: 0.9414 - val_loss: 0.1926 - val_accuracy: 0.9270\n",
      "Epoch 95/5000\n",
      "180/180 [==============================] - 0s 910us/step - loss: 0.1530 - accuracy: 0.9402 - val_loss: 0.1928 - val_accuracy: 0.9230\n",
      "Epoch 96/5000\n",
      "180/180 [==============================] - 0s 902us/step - loss: 0.1515 - accuracy: 0.9381 - val_loss: 0.1852 - val_accuracy: 0.9310\n",
      "Epoch 97/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1526 - accuracy: 0.9383 - val_loss: 0.1965 - val_accuracy: 0.9240\n",
      "Epoch 98/5000\n",
      "180/180 [==============================] - 0s 885us/step - loss: 0.1497 - accuracy: 0.9410 - val_loss: 0.1965 - val_accuracy: 0.9300\n",
      "Epoch 99/5000\n",
      "180/180 [==============================] - 0s 905us/step - loss: 0.1520 - accuracy: 0.9390 - val_loss: 0.1911 - val_accuracy: 0.9290\n",
      "Epoch 100/5000\n",
      "180/180 [==============================] - 0s 889us/step - loss: 0.1513 - accuracy: 0.9409 - val_loss: 0.1961 - val_accuracy: 0.9200\n",
      "Epoch 101/5000\n",
      "180/180 [==============================] - 0s 897us/step - loss: 0.1492 - accuracy: 0.9404 - val_loss: 0.1893 - val_accuracy: 0.9260\n",
      "Epoch 102/5000\n",
      "180/180 [==============================] - 0s 912us/step - loss: 0.1491 - accuracy: 0.9430 - val_loss: 0.1978 - val_accuracy: 0.9240\n",
      "Epoch 103/5000\n",
      "180/180 [==============================] - 0s 919us/step - loss: 0.1483 - accuracy: 0.9398 - val_loss: 0.1998 - val_accuracy: 0.9250\n",
      "Epoch 104/5000\n",
      "180/180 [==============================] - 0s 913us/step - loss: 0.1492 - accuracy: 0.9433 - val_loss: 0.1927 - val_accuracy: 0.9280\n",
      "Epoch 105/5000\n",
      "180/180 [==============================] - 0s 902us/step - loss: 0.1488 - accuracy: 0.9423 - val_loss: 0.1914 - val_accuracy: 0.9280\n",
      "Epoch 106/5000\n",
      "180/180 [==============================] - 0s 901us/step - loss: 0.1485 - accuracy: 0.9412 - val_loss: 0.1879 - val_accuracy: 0.9270\n",
      "Epoch 107/5000\n",
      "180/180 [==============================] - 0s 927us/step - loss: 0.1486 - accuracy: 0.9431 - val_loss: 0.1948 - val_accuracy: 0.9200\n",
      "Epoch 108/5000\n",
      "180/180 [==============================] - 0s 880us/step - loss: 0.1487 - accuracy: 0.9424 - val_loss: 0.1876 - val_accuracy: 0.9290\n",
      "Epoch 109/5000\n",
      "180/180 [==============================] - 0s 912us/step - loss: 0.1478 - accuracy: 0.9427 - val_loss: 0.1882 - val_accuracy: 0.9300\n",
      "Epoch 110/5000\n",
      "180/180 [==============================] - 0s 889us/step - loss: 0.1468 - accuracy: 0.9426 - val_loss: 0.1862 - val_accuracy: 0.9280\n",
      "Epoch 111/5000\n",
      "180/180 [==============================] - 0s 879us/step - loss: 0.1473 - accuracy: 0.9429 - val_loss: 0.1931 - val_accuracy: 0.9230\n",
      "Epoch 112/5000\n",
      "180/180 [==============================] - 0s 885us/step - loss: 0.1475 - accuracy: 0.9404 - val_loss: 0.1938 - val_accuracy: 0.9260\n",
      "Epoch 113/5000\n",
      "180/180 [==============================] - 0s 884us/step - loss: 0.1456 - accuracy: 0.9437 - val_loss: 0.1977 - val_accuracy: 0.9250\n",
      "Epoch 114/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1447 - accuracy: 0.9438 - val_loss: 0.1927 - val_accuracy: 0.9270\n",
      "Epoch 115/5000\n",
      "180/180 [==============================] - 0s 911us/step - loss: 0.1463 - accuracy: 0.9401 - val_loss: 0.1956 - val_accuracy: 0.9230\n",
      "Epoch 116/5000\n",
      "180/180 [==============================] - 0s 920us/step - loss: 0.1457 - accuracy: 0.9412 - val_loss: 0.1934 - val_accuracy: 0.9220\n",
      "Epoch 117/5000\n",
      "180/180 [==============================] - 0s 903us/step - loss: 0.1469 - accuracy: 0.9424 - val_loss: 0.2035 - val_accuracy: 0.9180\n",
      "Epoch 118/5000\n",
      "180/180 [==============================] - 0s 907us/step - loss: 0.1431 - accuracy: 0.9463 - val_loss: 0.1869 - val_accuracy: 0.9300\n",
      "Epoch 119/5000\n",
      "180/180 [==============================] - 0s 886us/step - loss: 0.1440 - accuracy: 0.9432 - val_loss: 0.1927 - val_accuracy: 0.9290\n",
      "Epoch 120/5000\n",
      "180/180 [==============================] - 0s 926us/step - loss: 0.1465 - accuracy: 0.9408 - val_loss: 0.1923 - val_accuracy: 0.9230\n",
      "Epoch 121/5000\n",
      "180/180 [==============================] - 0s 903us/step - loss: 0.1448 - accuracy: 0.9426 - val_loss: 0.1952 - val_accuracy: 0.9220\n",
      "Epoch 122/5000\n",
      "180/180 [==============================] - 0s 917us/step - loss: 0.1434 - accuracy: 0.9447 - val_loss: 0.1917 - val_accuracy: 0.9290\n",
      "Epoch 123/5000\n",
      "180/180 [==============================] - 0s 942us/step - loss: 0.1428 - accuracy: 0.9433 - val_loss: 0.1944 - val_accuracy: 0.9240\n",
      "Epoch 124/5000\n",
      "180/180 [==============================] - 0s 924us/step - loss: 0.1422 - accuracy: 0.9423 - val_loss: 0.1912 - val_accuracy: 0.9290\n",
      "Epoch 125/5000\n",
      "180/180 [==============================] - 0s 924us/step - loss: 0.1438 - accuracy: 0.9458 - val_loss: 0.2010 - val_accuracy: 0.9270\n",
      "Epoch 126/5000\n",
      "180/180 [==============================] - 0s 940us/step - loss: 0.1418 - accuracy: 0.9451 - val_loss: 0.1963 - val_accuracy: 0.9330\n",
      "Epoch 127/5000\n",
      "180/180 [==============================] - 0s 918us/step - loss: 0.1458 - accuracy: 0.9429 - val_loss: 0.1962 - val_accuracy: 0.9210\n",
      "Epoch 128/5000\n",
      "180/180 [==============================] - 0s 889us/step - loss: 0.1444 - accuracy: 0.9436 - val_loss: 0.1897 - val_accuracy: 0.9250\n",
      "Epoch 129/5000\n",
      "180/180 [==============================] - 0s 890us/step - loss: 0.1426 - accuracy: 0.9446 - val_loss: 0.2003 - val_accuracy: 0.9200\n",
      "Epoch 130/5000\n",
      "180/180 [==============================] - 0s 896us/step - loss: 0.1419 - accuracy: 0.9482 - val_loss: 0.2059 - val_accuracy: 0.9160\n",
      "Epoch 131/5000\n",
      "180/180 [==============================] - 0s 881us/step - loss: 0.1432 - accuracy: 0.9423 - val_loss: 0.1909 - val_accuracy: 0.9270\n",
      "Epoch 132/5000\n",
      "180/180 [==============================] - 0s 894us/step - loss: 0.1420 - accuracy: 0.9439 - val_loss: 0.1918 - val_accuracy: 0.9280\n",
      "Epoch 133/5000\n",
      "180/180 [==============================] - 0s 905us/step - loss: 0.1433 - accuracy: 0.9423 - val_loss: 0.1959 - val_accuracy: 0.9200\n",
      "Epoch 134/5000\n",
      "180/180 [==============================] - 0s 934us/step - loss: 0.1424 - accuracy: 0.9420 - val_loss: 0.2049 - val_accuracy: 0.9300\n",
      "Epoch 135/5000\n",
      "180/180 [==============================] - 0s 911us/step - loss: 0.1409 - accuracy: 0.9424 - val_loss: 0.1930 - val_accuracy: 0.9300\n",
      "Epoch 136/5000\n",
      "180/180 [==============================] - 0s 909us/step - loss: 0.1396 - accuracy: 0.9462 - val_loss: 0.2130 - val_accuracy: 0.9140\n",
      "Epoch 137/5000\n",
      "180/180 [==============================] - 0s 919us/step - loss: 0.1436 - accuracy: 0.9444 - val_loss: 0.1941 - val_accuracy: 0.9310\n",
      "Epoch 138/5000\n",
      "180/180 [==============================] - 0s 917us/step - loss: 0.1403 - accuracy: 0.9444 - val_loss: 0.2077 - val_accuracy: 0.9210\n",
      "Epoch 139/5000\n",
      "180/180 [==============================] - 0s 897us/step - loss: 0.1406 - accuracy: 0.9463 - val_loss: 0.2017 - val_accuracy: 0.9210\n",
      "Epoch 140/5000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9446 - val_loss: 0.1909 - val_accuracy: 0.9250\n",
      "Epoch 141/5000\n",
      "180/180 [==============================] - 0s 913us/step - loss: 0.1391 - accuracy: 0.9454 - val_loss: 0.1942 - val_accuracy: 0.9290\n",
      "Epoch 142/5000\n",
      "180/180 [==============================] - 0s 887us/step - loss: 0.1381 - accuracy: 0.9446 - val_loss: 0.1968 - val_accuracy: 0.9250\n",
      "Epoch 143/5000\n",
      "180/180 [==============================] - 0s 893us/step - loss: 0.1393 - accuracy: 0.9456 - val_loss: 0.1962 - val_accuracy: 0.9330\n",
      "Epoch 144/5000\n",
      "180/180 [==============================] - 0s 880us/step - loss: 0.1397 - accuracy: 0.9439 - val_loss: 0.2027 - val_accuracy: 0.9250\n",
      "Epoch 145/5000\n",
      "180/180 [==============================] - 0s 887us/step - loss: 0.1399 - accuracy: 0.9453 - val_loss: 0.2027 - val_accuracy: 0.9230\n",
      "Epoch 146/5000\n",
      "180/180 [==============================] - 0s 906us/step - loss: 0.1404 - accuracy: 0.9451 - val_loss: 0.1987 - val_accuracy: 0.9310\n",
      "Epoch 147/5000\n",
      "180/180 [==============================] - 0s 906us/step - loss: 0.1394 - accuracy: 0.9443 - val_loss: 0.2005 - val_accuracy: 0.9170\n",
      "Epoch 148/5000\n",
      "180/180 [==============================] - 0s 916us/step - loss: 0.1392 - accuracy: 0.9450 - val_loss: 0.1927 - val_accuracy: 0.9240\n",
      "Epoch 149/5000\n",
      "180/180 [==============================] - 0s 907us/step - loss: 0.1399 - accuracy: 0.9436 - val_loss: 0.1995 - val_accuracy: 0.9240\n",
      "Epoch 150/5000\n",
      "180/180 [==============================] - 0s 922us/step - loss: 0.1381 - accuracy: 0.9442 - val_loss: 0.2012 - val_accuracy: 0.9200\n",
      "Epoch 151/5000\n",
      "180/180 [==============================] - 0s 922us/step - loss: 0.1392 - accuracy: 0.9439 - val_loss: 0.1974 - val_accuracy: 0.9270\n",
      "Epoch 152/5000\n",
      "180/180 [==============================] - 0s 933us/step - loss: 0.1369 - accuracy: 0.9439 - val_loss: 0.1984 - val_accuracy: 0.9200\n",
      "Epoch 153/5000\n",
      "180/180 [==============================] - 0s 901us/step - loss: 0.1379 - accuracy: 0.9429 - val_loss: 0.1978 - val_accuracy: 0.9190\n",
      "Epoch 154/5000\n",
      "180/180 [==============================] - 0s 894us/step - loss: 0.1379 - accuracy: 0.9457 - val_loss: 0.1986 - val_accuracy: 0.9180\n",
      "Epoch 155/5000\n",
      "180/180 [==============================] - 0s 923us/step - loss: 0.1370 - accuracy: 0.9446 - val_loss: 0.1995 - val_accuracy: 0.9170\n",
      "Epoch 156/5000\n",
      "180/180 [==============================] - 0s 913us/step - loss: 0.1360 - accuracy: 0.9463 - val_loss: 0.1959 - val_accuracy: 0.9210\n",
      "Epoch 157/5000\n",
      "180/180 [==============================] - 0s 906us/step - loss: 0.1377 - accuracy: 0.9457 - val_loss: 0.1947 - val_accuracy: 0.9270\n",
      "Epoch 158/5000\n",
      "180/180 [==============================] - 0s 913us/step - loss: 0.1352 - accuracy: 0.9473 - val_loss: 0.2034 - val_accuracy: 0.9230\n",
      "Epoch 159/5000\n",
      "180/180 [==============================] - 0s 909us/step - loss: 0.1375 - accuracy: 0.9443 - val_loss: 0.1997 - val_accuracy: 0.9240\n",
      "Epoch 160/5000\n",
      "180/180 [==============================] - 0s 896us/step - loss: 0.1378 - accuracy: 0.9458 - val_loss: 0.2004 - val_accuracy: 0.9180\n",
      "Epoch 161/5000\n",
      "180/180 [==============================] - 0s 875us/step - loss: 0.1376 - accuracy: 0.9456 - val_loss: 0.1979 - val_accuracy: 0.9240\n",
      "Epoch 162/5000\n",
      "180/180 [==============================] - 0s 894us/step - loss: 0.1352 - accuracy: 0.9469 - val_loss: 0.2027 - val_accuracy: 0.9160\n",
      "Epoch 163/5000\n",
      "180/180 [==============================] - 0s 894us/step - loss: 0.1376 - accuracy: 0.9462 - val_loss: 0.2275 - val_accuracy: 0.9150\n",
      "Epoch 164/5000\n",
      "180/180 [==============================] - 0s 922us/step - loss: 0.1391 - accuracy: 0.9448 - val_loss: 0.2069 - val_accuracy: 0.9190\n",
      "Epoch 165/5000\n",
      "180/180 [==============================] - 0s 916us/step - loss: 0.1369 - accuracy: 0.9461 - val_loss: 0.2067 - val_accuracy: 0.9190\n",
      "Epoch 166/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1363 - accuracy: 0.9477 - val_loss: 0.1980 - val_accuracy: 0.9200\n",
      "Epoch 167/5000\n",
      "180/180 [==============================] - 0s 893us/step - loss: 0.1359 - accuracy: 0.9478 - val_loss: 0.1988 - val_accuracy: 0.9210\n",
      "Epoch 168/5000\n",
      "180/180 [==============================] - 0s 898us/step - loss: 0.1370 - accuracy: 0.9456 - val_loss: 0.2011 - val_accuracy: 0.9230\n",
      "Epoch 169/5000\n",
      "180/180 [==============================] - 0s 907us/step - loss: 0.1388 - accuracy: 0.9451 - val_loss: 0.2033 - val_accuracy: 0.9220\n",
      "Epoch 170/5000\n",
      "180/180 [==============================] - 0s 895us/step - loss: 0.1380 - accuracy: 0.9460 - val_loss: 0.2080 - val_accuracy: 0.9170\n",
      "Epoch 171/5000\n",
      "180/180 [==============================] - 0s 923us/step - loss: 0.1347 - accuracy: 0.9471 - val_loss: 0.2063 - val_accuracy: 0.9250\n",
      "Epoch 172/5000\n",
      "180/180 [==============================] - 0s 924us/step - loss: 0.1365 - accuracy: 0.9446 - val_loss: 0.2001 - val_accuracy: 0.9310\n",
      "Epoch 173/5000\n",
      "180/180 [==============================] - 0s 914us/step - loss: 0.1331 - accuracy: 0.9480 - val_loss: 0.2071 - val_accuracy: 0.9170\n",
      "Epoch 174/5000\n",
      "180/180 [==============================] - 0s 926us/step - loss: 0.1350 - accuracy: 0.9470 - val_loss: 0.1944 - val_accuracy: 0.9220\n",
      "Epoch 175/5000\n",
      "180/180 [==============================] - 0s 927us/step - loss: 0.1335 - accuracy: 0.9472 - val_loss: 0.2030 - val_accuracy: 0.9250\n",
      "Epoch 176/5000\n",
      "180/180 [==============================] - 0s 905us/step - loss: 0.1342 - accuracy: 0.9474 - val_loss: 0.1982 - val_accuracy: 0.9200\n",
      "Epoch 177/5000\n",
      "180/180 [==============================] - 0s 890us/step - loss: 0.1343 - accuracy: 0.9484 - val_loss: 0.1983 - val_accuracy: 0.9310\n",
      "Epoch 178/5000\n",
      "180/180 [==============================] - 0s 904us/step - loss: 0.1351 - accuracy: 0.9479 - val_loss: 0.2164 - val_accuracy: 0.9200\n",
      "Epoch 179/5000\n",
      "180/180 [==============================] - 0s 899us/step - loss: 0.1336 - accuracy: 0.9443 - val_loss: 0.2004 - val_accuracy: 0.9280\n",
      "Epoch 180/5000\n",
      "180/180 [==============================] - 0s 898us/step - loss: 0.1335 - accuracy: 0.9486 - val_loss: 0.1984 - val_accuracy: 0.9250\n",
      "Epoch 181/5000\n",
      "180/180 [==============================] - 0s 877us/step - loss: 0.1330 - accuracy: 0.9484 - val_loss: 0.2073 - val_accuracy: 0.9190\n",
      "Epoch 182/5000\n",
      "180/180 [==============================] - 0s 912us/step - loss: 0.1340 - accuracy: 0.9468 - val_loss: 0.1954 - val_accuracy: 0.9240\n",
      "Epoch 183/5000\n",
      "180/180 [==============================] - 0s 908us/step - loss: 0.1338 - accuracy: 0.9473 - val_loss: 0.2049 - val_accuracy: 0.9250\n",
      "Model: \"dnn_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            multiple                  560       \n",
      "                                                                 \n",
      " dense_53 (Dense)            multiple                  170       \n",
      "                                                                 \n",
      " dense_54 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_55 (Dense)            multiple                  110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 840\n",
      "Trainable params: 840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 30.4 s (started: 2021-12-21 04:24:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "class DNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(DNN,self).__init__()\n",
    "    # self.dense1 = tf.keras.layers.Dense(24, activation=tf.nn.relu,\n",
    "                                        # kernel_regularizer=regularizers.l1_l2(l1=1e-7, l2=1e-7),\n",
    "                                        # bias_regularizer=regularizers.l2(1e-7),)\n",
    "    self.dense1 = tf.keras.layers.Dense(16, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(10, activation=tf.nn.relu)\n",
    "    self.dense3 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    # x = self.dense3(x)\n",
    "    return self.output_layer(x)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-1e-2)\n",
    "\n",
    "\n",
    "callback_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 5000\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model = DNN()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[callback_early], verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold=0.9 => Number of None is 738\n",
      "threshold=0.8 => Number of None is 479\n",
      "threshold=0.7 => Number of None is 306\n",
      "threshold=0.6 => Number of None is 160\n",
      "threshold=0.5 => Number of None is 2\n",
      "threshold=0.4 => Number of None is 0\n",
      "time: 72.4 ms (started: 2021-12-21 03:54:42 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from pandas import RangeIndex\n",
    "\n",
    "nn_pred = model.predict(test_x)\n",
    "for i in range(,0,-1):\n",
    "    thres = i/10\n",
    "    pred = np.where(nn_pred<thres, 0, 1)\n",
    "    output = ohenc.inverse_transform(pred)\n",
    "    check = (output==None).sum()\n",
    "    print(f\"threshold={thres} => Number of None is {check}\")\n",
    "    if check==0:break\n",
    "\n",
    "if check==0:\n",
    "    pd.Series(output.reshape(-1), index=RangeIndex(1, 2001), name='Predicted').to_csv('ans_nn_4.csv',index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
