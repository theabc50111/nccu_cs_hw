{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_15613/2577044405.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 02:30:16.498629: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 02:30:19.358969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:19.359467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:19.452364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:19.465837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:19.466280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:19.466718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.602858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.603395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.619861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.620306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.620750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.621188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 9648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-21 02:30:31.675882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 02:30:31.676297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 9648 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.557571</td>\n",
       "      <td>11.846020</td>\n",
       "      <td>15.020207</td>\n",
       "      <td>2.623484</td>\n",
       "      <td>15.538517</td>\n",
       "      <td>2.341611</td>\n",
       "      <td>5.829028</td>\n",
       "      <td>7.586709</td>\n",
       "      <td>13.331953</td>\n",
       "      <td>8.304782</td>\n",
       "      <td>-8.980424</td>\n",
       "      <td>-1.978135</td>\n",
       "      <td>-9.056215</td>\n",
       "      <td>0.601958</td>\n",
       "      <td>-3.990212</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>-8.435632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.031884</td>\n",
       "      <td>4.314536</td>\n",
       "      <td>19.694838</td>\n",
       "      <td>15.264186</td>\n",
       "      <td>7.054585</td>\n",
       "      <td>0.382333</td>\n",
       "      <td>4.650885</td>\n",
       "      <td>11.331481</td>\n",
       "      <td>12.492329</td>\n",
       "      <td>12.877221</td>\n",
       "      <td>-1.788222</td>\n",
       "      <td>-12.520625</td>\n",
       "      <td>1.183564</td>\n",
       "      <td>2.312428</td>\n",
       "      <td>-5.997316</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>13.314504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.986272</td>\n",
       "      <td>6.139161</td>\n",
       "      <td>21.949963</td>\n",
       "      <td>5.590123</td>\n",
       "      <td>16.445212</td>\n",
       "      <td>2.213986</td>\n",
       "      <td>2.393948</td>\n",
       "      <td>16.885378</td>\n",
       "      <td>8.114116</td>\n",
       "      <td>20.133208</td>\n",
       "      <td>12.148553</td>\n",
       "      <td>-11.400213</td>\n",
       "      <td>15.273799</td>\n",
       "      <td>2.714855</td>\n",
       "      <td>6.574276</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>8.964849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.584971</td>\n",
       "      <td>11.598161</td>\n",
       "      <td>9.793109</td>\n",
       "      <td>11.873020</td>\n",
       "      <td>6.645073</td>\n",
       "      <td>3.346882</td>\n",
       "      <td>4.445008</td>\n",
       "      <td>13.218360</td>\n",
       "      <td>8.495786</td>\n",
       "      <td>17.403693</td>\n",
       "      <td>-3.371434</td>\n",
       "      <td>-1.329931</td>\n",
       "      <td>4.307364</td>\n",
       "      <td>1.217894</td>\n",
       "      <td>-1.730330</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>13.563612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.625079</td>\n",
       "      <td>12.517998</td>\n",
       "      <td>15.522108</td>\n",
       "      <td>18.269750</td>\n",
       "      <td>1.508771</td>\n",
       "      <td>3.078033</td>\n",
       "      <td>5.224333</td>\n",
       "      <td>18.335198</td>\n",
       "      <td>9.604704</td>\n",
       "      <td>19.732707</td>\n",
       "      <td>3.192207</td>\n",
       "      <td>2.195230</td>\n",
       "      <td>10.903963</td>\n",
       "      <td>2.317327</td>\n",
       "      <td>1.379398</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>-8.590211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0         f1         f2         f3         f4        f5        f6  \\\n",
       "0  14.557571  11.846020  15.020207   2.623484  15.538517  2.341611  5.829028   \n",
       "1  17.031884   4.314536  19.694838  15.264186   7.054585  0.382333  4.650885   \n",
       "2  24.986272   6.139161  21.949963   5.590123  16.445212  2.213986  2.393948   \n",
       "3   7.584971  11.598161   9.793109  11.873020   6.645073  3.346882  4.445008   \n",
       "4  11.625079  12.517998  15.522108  18.269750   1.508771  3.078033  5.224333   \n",
       "\n",
       "          f7         f8         f9        f10        f11        f12       f13  \\\n",
       "0   7.586709  13.331953   8.304782  -8.980424  -1.978135  -9.056215  0.601958   \n",
       "1  11.331481  12.492329  12.877221  -1.788222 -12.520625   1.183564  2.312428   \n",
       "2  16.885378   8.114116  20.133208  12.148553 -11.400213  15.273799  2.714855   \n",
       "3  13.218360   8.495786  17.403693  -3.371434  -1.329931   4.307364  1.217894   \n",
       "4  18.335198   9.604704  19.732707   3.192207   2.195230  10.903963  2.317327   \n",
       "\n",
       "        f14 f15 f16 f17        f18  \n",
       "0 -3.990212   F   F   A  -8.435632  \n",
       "1 -5.997316   F   A   F  13.314504  \n",
       "2  6.574276   A   C   F   8.964849  \n",
       "3 -1.730330   D   D   B  13.563612  \n",
       "4  1.379398   B   C   B  -8.590211  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    G\n",
       "2    G\n",
       "3    H\n",
       "4    F\n",
       "Name: target, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.981599</td>\n",
       "      <td>14.926975</td>\n",
       "      <td>14.055879</td>\n",
       "      <td>12.940302</td>\n",
       "      <td>6.547128</td>\n",
       "      <td>3.765283</td>\n",
       "      <td>4.911310</td>\n",
       "      <td>12.816209</td>\n",
       "      <td>12.321573</td>\n",
       "      <td>17.026134</td>\n",
       "      <td>-4.435416</td>\n",
       "      <td>-3.338954</td>\n",
       "      <td>5.145203</td>\n",
       "      <td>0.790691</td>\n",
       "      <td>-2.833418</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>-3.198949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.898603</td>\n",
       "      <td>8.866915</td>\n",
       "      <td>20.358121</td>\n",
       "      <td>6.067027</td>\n",
       "      <td>13.505201</td>\n",
       "      <td>1.742242</td>\n",
       "      <td>3.731071</td>\n",
       "      <td>14.026740</td>\n",
       "      <td>13.686651</td>\n",
       "      <td>17.920196</td>\n",
       "      <td>3.398008</td>\n",
       "      <td>-4.949895</td>\n",
       "      <td>2.115480</td>\n",
       "      <td>1.839801</td>\n",
       "      <td>2.199004</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>E</td>\n",
       "      <td>10.497858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.817003</td>\n",
       "      <td>5.789936</td>\n",
       "      <td>20.937223</td>\n",
       "      <td>8.249511</td>\n",
       "      <td>13.569874</td>\n",
       "      <td>0.060766</td>\n",
       "      <td>5.505705</td>\n",
       "      <td>7.102595</td>\n",
       "      <td>12.735801</td>\n",
       "      <td>7.195690</td>\n",
       "      <td>10.580991</td>\n",
       "      <td>-5.864917</td>\n",
       "      <td>-2.386709</td>\n",
       "      <td>2.558099</td>\n",
       "      <td>5.790495</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>-11.909326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.994456</td>\n",
       "      <td>12.242201</td>\n",
       "      <td>7.906568</td>\n",
       "      <td>10.475264</td>\n",
       "      <td>14.327991</td>\n",
       "      <td>0.856716</td>\n",
       "      <td>4.754537</td>\n",
       "      <td>26.673467</td>\n",
       "      <td>6.219800</td>\n",
       "      <td>21.140358</td>\n",
       "      <td>-11.304655</td>\n",
       "      <td>-8.923086</td>\n",
       "      <td>5.620824</td>\n",
       "      <td>1.436804</td>\n",
       "      <td>-6.877449</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.256432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.640119</td>\n",
       "      <td>11.944469</td>\n",
       "      <td>14.674074</td>\n",
       "      <td>13.246914</td>\n",
       "      <td>5.013325</td>\n",
       "      <td>2.332369</td>\n",
       "      <td>4.226819</td>\n",
       "      <td>6.004056</td>\n",
       "      <td>11.400005</td>\n",
       "      <td>6.236202</td>\n",
       "      <td>1.708020</td>\n",
       "      <td>12.079740</td>\n",
       "      <td>16.079740</td>\n",
       "      <td>1.037320</td>\n",
       "      <td>5.126897</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>12.142437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0         f1         f2         f3         f4        f5        f6  \\\n",
       "0  12.981599  14.926975  14.055879  12.940302   6.547128  3.765283  4.911310   \n",
       "1  26.898603   8.866915  20.358121   6.067027  13.505201  1.742242  3.731071   \n",
       "2  20.817003   5.789936  20.937223   8.249511  13.569874  0.060766  5.505705   \n",
       "3   9.994456  12.242201   7.906568  10.475264  14.327991  0.856716  4.754537   \n",
       "4   8.640119  11.944469  14.674074  13.246914   5.013325  2.332369  4.226819   \n",
       "\n",
       "          f7         f8         f9        f10        f11        f12       f13  \\\n",
       "0  12.816209  12.321573  17.026134  -4.435416  -3.338954   5.145203  0.790691   \n",
       "1  14.026740  13.686651  17.920196   3.398008  -4.949895   2.115480  1.839801   \n",
       "2   7.102595  12.735801   7.195690  10.580991  -5.864917  -2.386709  2.558099   \n",
       "3  26.673467   6.219800  21.140358 -11.304655  -8.923086   5.620824  1.436804   \n",
       "4   6.004056  11.400005   6.236202   1.708020  12.079740  16.079740  1.037320   \n",
       "\n",
       "        f14 f15 f16 f17        f18  \n",
       "0 -2.833418   E   D   A  -3.198949  \n",
       "1  2.199004   F   F   E  10.497858  \n",
       "2  5.790495   F   F   F -11.909326  \n",
       "3 -6.877449   C   B   A  -0.256432  \n",
       "4  5.126897   A   C   D  12.142437  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45 s (started: 2021-12-21 02:29:47 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "train_df = pd.read_csv('task3_2021.training.csv')\n",
    "test_df = pd.read_csv('task3_2021.test.csv')\n",
    "n_pre_train_y = train_df['target']\n",
    "n_pre_train_x = train_df.drop(['target'], axis=1)\n",
    "n_pre_test_x = test_df\n",
    "# display(n_pre_train_x.head(), n_pre_train_y.head(), n_pre_train_y.nunique(), n_pre_test_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 402 ms (started: 2021-12-21 02:30:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def oh_pre(x):\n",
    "    for k in ['f15', 'f16', 'f17']:\n",
    "        tmp_one_hot_k =  pd.get_dummies(x[k], prefix=f\"{k}\")\n",
    "        x = pd.concat([x, tmp_one_hot_k],axis=1)\n",
    "        x = x.drop([k], axis=1)\n",
    "    return x\n",
    "\n",
    "oh_pre_train_x = oh_pre(n_pre_train_x)\n",
    "oh_pre_test_x = oh_pre(n_pre_test_x)\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(oh_pre_train_x)\n",
    "test_x = scaler.transform(oh_pre_test_x)\n",
    "\n",
    "ohenc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "train_y = ohenc.fit_transform(n_pre_train_y.values.reshape(-1,1))\n",
    "# mse = make_scorer(mean_squared_error, squared=False)nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "90/90 [==============================] - 8s 33ms/step - loss: 2.0402 - accuracy: 0.2239 - val_loss: 1.6177 - val_accuracy: 0.3370 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.2730 - accuracy: 0.4888 - val_loss: 1.0135 - val_accuracy: 0.5550 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.8089 - accuracy: 0.6812 - val_loss: 0.6826 - val_accuracy: 0.7200 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.5846 - accuracy: 0.7797 - val_loss: 0.5198 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.4669 - accuracy: 0.8259 - val_loss: 0.4298 - val_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.3944 - accuracy: 0.8498 - val_loss: 0.3727 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.3582 - accuracy: 0.8599 - val_loss: 0.3478 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.3140 - accuracy: 0.8766 - val_loss: 0.3460 - val_accuracy: 0.8510 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.2908 - accuracy: 0.8860 - val_loss: 0.3282 - val_accuracy: 0.8730 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.2710 - accuracy: 0.8919 - val_loss: 0.3362 - val_accuracy: 0.8570 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.2628 - accuracy: 0.8946 - val_loss: 0.2855 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.2432 - accuracy: 0.9036 - val_loss: 0.2692 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.2341 - accuracy: 0.9080 - val_loss: 0.2756 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.2225 - accuracy: 0.9149 - val_loss: 0.2773 - val_accuracy: 0.8830 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.2147 - accuracy: 0.9150 - val_loss: 0.2633 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.2052 - accuracy: 0.9168 - val_loss: 0.2646 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.2002 - accuracy: 0.9177 - val_loss: 0.2676 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.1932 - accuracy: 0.9241 - val_loss: 0.2724 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1941 - accuracy: 0.9193 - val_loss: 0.2575 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1836 - accuracy: 0.9257 - val_loss: 0.2788 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1759 - accuracy: 0.9293 - val_loss: 0.2545 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1728 - accuracy: 0.9318 - val_loss: 0.2468 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.1691 - accuracy: 0.9320 - val_loss: 0.2546 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1626 - accuracy: 0.9368 - val_loss: 0.2784 - val_accuracy: 0.8790 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.1685 - accuracy: 0.9324 - val_loss: 0.3211 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1638 - accuracy: 0.9337 - val_loss: 0.2646 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1538 - accuracy: 0.9379 - val_loss: 0.2517 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1462 - accuracy: 0.9457 - val_loss: 0.2528 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1472 - accuracy: 0.9441 - val_loss: 0.2543 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1433 - accuracy: 0.9442 - val_loss: 0.2536 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1419 - accuracy: 0.9458 - val_loss: 0.2450 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "90/90 [==============================] - 1s 17ms/step - loss: 0.1362 - accuracy: 0.9481 - val_loss: 0.2602 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.1359 - accuracy: 0.9471 - val_loss: 0.2624 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "90/90 [==============================] - 1s 17ms/step - loss: 0.1358 - accuracy: 0.9472 - val_loss: 0.2577 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.1421 - accuracy: 0.9423 - val_loss: 0.2514 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.1298 - accuracy: 0.9496 - val_loss: 0.2632 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1344 - accuracy: 0.9438 - val_loss: 0.2703 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.1297 - accuracy: 0.9492 - val_loss: 0.2728 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.1297 - accuracy: 0.9490 - val_loss: 0.2809 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 0.1219 - accuracy: 0.9516 - val_loss: 0.2726 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.1167 - accuracy: 0.9537 - val_loss: 0.2481 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Model: \"dnn_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             multiple                  1680      \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  2352      \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  2352      \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,874\n",
      "Trainable params: 6,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 1min 3s (started: 2021-12-21 02:38:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class DNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(DNN,self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.dense3 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    x = self.dense3(x)\n",
    "    return self.output_layer(x)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    elif epoch < 90:\n",
    "        return lr*tf.math.exp(1e-1)\n",
    "\n",
    "\n",
    "callback_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 1000\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model = DNN()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[callback_lr,callback_early], verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2978238e-15, 1.0525484e-11, 8.8355155e-04, ..., 1.7472745e-04,\n",
       "       9.9976677e-01, 5.8548019e-05], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.4 s (started: 2021-12-21 02:43:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.29 s (started: 2021-12-21 02:49:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from pandas import RangeIndex\n",
    "\n",
    "nn_pred = model.predict(test_x)\n",
    "\n",
    "\n",
    "pred = np.where(nn_pred<0.5, 0, 1)\n",
    "output = ohenc.inverse_transform(pred)\n",
    "check = (output==None).sum()\n",
    "if check==0:\n",
    "    pd.Series(output, index=RangeIndex(1, 2001), name='Predicted').to_csv('ans_nn_1.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
