{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21831/1371881661.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 03:06:10.074229: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 03:06:11.156848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.157336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.161435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.161882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.162317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.162755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.002572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.011186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.011629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.016183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.016616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.017051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 9648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-21 03:06:15.040121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.040529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 9648 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "time: 16.6 s (started: 2021-12-21 03:05:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "train_df = pd.read_csv('task3_2021.training.csv')\n",
    "test_df = pd.read_csv('task3_2021.test.csv')\n",
    "n_pre_train_y = train_df['target']\n",
    "n_pre_train_x = train_df.drop(['target'], axis=1)\n",
    "n_pre_test_x = test_df\n",
    "# display(n_pre_train_x.head(), n_pre_train_y.head(), n_pre_train_y.nunique(), n_pre_test_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 126 ms (started: 2021-12-21 03:06:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def oh_pre(x):\n",
    "    for k in ['f15', 'f16', 'f17']:\n",
    "        tmp_one_hot_k =  pd.get_dummies(x[k], prefix=f\"{k}\")\n",
    "        x = pd.concat([x, tmp_one_hot_k],axis=1)\n",
    "        x = x.drop([k], axis=1)\n",
    "    return x\n",
    "\n",
    "oh_pre_train_x = oh_pre(n_pre_train_x)\n",
    "oh_pre_test_x = oh_pre(n_pre_test_x)\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(oh_pre_train_x)\n",
    "test_x = scaler.transform(oh_pre_test_x)\n",
    "\n",
    "ohenc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "train_y = ohenc.fit_transform(n_pre_train_y.values.reshape(-1,1))\n",
    "# mse = make_scorer(mean_squared_error, squared=False)nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "180/180 [==============================] - 1s 2ms/step - loss: 2.0555 - accuracy: 0.2367 - val_loss: 1.7813 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 1.6280 - accuracy: 0.3656 - val_loss: 1.5010 - val_accuracy: 0.3890 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 1.3940 - accuracy: 0.4534 - val_loss: 1.3155 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 1.2297 - accuracy: 0.5281 - val_loss: 1.1809 - val_accuracy: 0.5240 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 1.1047 - accuracy: 0.5883 - val_loss: 1.0722 - val_accuracy: 0.5860 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 1.0056 - accuracy: 0.6423 - val_loss: 0.9842 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.9240 - accuracy: 0.6857 - val_loss: 0.9124 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.8557 - accuracy: 0.7193 - val_loss: 0.8461 - val_accuracy: 0.7200 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.7975 - accuracy: 0.7481 - val_loss: 0.7935 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.7718 - val_loss: 0.7479 - val_accuracy: 0.7540 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.7917 - val_loss: 0.7077 - val_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.8070 - val_loss: 0.6769 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.8204 - val_loss: 0.6377 - val_accuracy: 0.7970 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.8354 - val_loss: 0.6078 - val_accuracy: 0.8170 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.8439 - val_loss: 0.5848 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.8546 - val_loss: 0.5622 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.8631 - val_loss: 0.5339 - val_accuracy: 0.8470 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.8707 - val_loss: 0.5238 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8727 - val_loss: 0.5021 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8792 - val_loss: 0.4785 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.8868 - val_loss: 0.4654 - val_accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8867 - val_loss: 0.4558 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8941 - val_loss: 0.4411 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8970 - val_loss: 0.4268 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8988 - val_loss: 0.4133 - val_accuracy: 0.8790 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8991 - val_loss: 0.4049 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.9049 - val_loss: 0.3997 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.9079 - val_loss: 0.3932 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.9089 - val_loss: 0.3827 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.9131 - val_loss: 0.3713 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.9138 - val_loss: 0.3693 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.9163 - val_loss: 0.3661 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.9144 - val_loss: 0.3585 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.9179 - val_loss: 0.3574 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.9194 - val_loss: 0.3507 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.9234 - val_loss: 0.3467 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.9230 - val_loss: 0.3376 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.9248 - val_loss: 0.3360 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.9283 - val_loss: 0.3307 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.9279 - val_loss: 0.3270 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.9280 - val_loss: 0.3215 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.9286 - val_loss: 0.3236 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9288 - val_loss: 0.3168 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.9313 - val_loss: 0.3148 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.9317 - val_loss: 0.3126 - val_accuracy: 0.8990 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.9312 - val_loss: 0.3069 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9318 - val_loss: 0.3050 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2593 - accuracy: 0.9336 - val_loss: 0.3035 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9339 - val_loss: 0.3011 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.9341 - val_loss: 0.2950 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9352 - val_loss: 0.3020 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9376 - val_loss: 0.2991 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.9342 - val_loss: 0.2939 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.9377 - val_loss: 0.2955 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9382 - val_loss: 0.2976 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9392 - val_loss: 0.2923 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9371 - val_loss: 0.2866 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9406 - val_loss: 0.2865 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9389 - val_loss: 0.2945 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.9394 - val_loss: 0.2918 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9421 - val_loss: 0.2892 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9411 - val_loss: 0.2824 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.9401 - val_loss: 0.2881 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9416 - val_loss: 0.2828 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9429 - val_loss: 0.2866 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9421 - val_loss: 0.2791 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9439 - val_loss: 0.2801 - val_accuracy: 0.9040 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9440 - val_loss: 0.2760 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9426 - val_loss: 0.2769 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9459 - val_loss: 0.2840 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9436 - val_loss: 0.2768 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9476 - val_loss: 0.2775 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9479 - val_loss: 0.2753 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9454 - val_loss: 0.2779 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9466 - val_loss: 0.2758 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9467 - val_loss: 0.2779 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.9457 - val_loss: 0.2690 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9482 - val_loss: 0.2707 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9453 - val_loss: 0.2697 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9480 - val_loss: 0.2759 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9502 - val_loss: 0.2706 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9462 - val_loss: 0.2754 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9500 - val_loss: 0.2687 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9503 - val_loss: 0.2750 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9504 - val_loss: 0.2766 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9506 - val_loss: 0.2745 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9492 - val_loss: 0.2733 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9502 - val_loss: 0.2665 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9501 - val_loss: 0.2765 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9494 - val_loss: 0.2700 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9518 - val_loss: 0.2721 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9497 - val_loss: 0.2718 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9532 - val_loss: 0.2669 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9526 - val_loss: 0.2657 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9533 - val_loss: 0.2743 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9511 - val_loss: 0.2718 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9514 - val_loss: 0.2659 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9546 - val_loss: 0.2751 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9523 - val_loss: 0.2678 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9541 - val_loss: 0.2672 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9542 - val_loss: 0.2687 - val_accuracy: 0.9070 - lr: 9.9005e-04\n",
      "Epoch 102/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9536 - val_loss: 0.2679 - val_accuracy: 0.9020 - lr: 9.8020e-04\n",
      "Epoch 103/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9551 - val_loss: 0.2785 - val_accuracy: 0.8990 - lr: 9.7045e-04\n",
      "Epoch 104/1000\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9528 - val_loss: 0.2739 - val_accuracy: 0.9100 - lr: 9.6079e-04\n",
      "Model: \"dnn_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            multiple                  1680      \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_30 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_31 (Dense)            multiple                  490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,170\n",
      "Trainable params: 2,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 27.3 s (started: 2021-12-21 03:46:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "class DNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(DNN,self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(48, activation=tf.nn.relu,\n",
    "                                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                        bias_regularizer=regularizers.l2(1e-4),)\n",
    "    self.dense2 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.dense3 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    # x = self.dense2(x)\n",
    "    # x = self.dense3(x)\n",
    "    return self.output_layer(x)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-1e-2)\n",
    "\n",
    "\n",
    "callback_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 1000\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model = DNN()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[callback_lr,callback_early], verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94.2 ms (started: 2021-12-21 03:52:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from pandas import RangeIndex\n",
    "\n",
    "nn_pred = model.predict(test_x)\n",
    "for i in range(1,10,-1):\n",
    "    thres = i/10\n",
    "    pred = np.where(nn_pred<thres, 0, 1)\n",
    "    output = ohenc.inverse_transform(pred)\n",
    "    check = (output==None).sum()\n",
    "    print(f\"threshold={thres} => Number of None is {check}\")\n",
    "    if check==0:break\n",
    "\n",
    "if check==0:\n",
    "    pd.Series(output.reshape(-1), index=RangeIndex(1, 2001), name='Predicted').to_csv('ans_nn_3.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 511 Âµs (started: 2021-12-21 03:52:50 +00:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10,1):\n",
    "    thres = i/10\n",
    "    print(thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9, 8, 7, 6, 5, 4, 3, 2]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.27 ms (started: 2021-12-21 03:54:16 +00:00)\n"
     ]
    }
   ],
   "source": [
    "list(range(9, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
