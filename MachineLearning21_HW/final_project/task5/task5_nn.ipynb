{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21831/1371881661.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 03:06:10.074229: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 03:06:11.156848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.157336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.161435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.161882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.162317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:11.162755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.002572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.011186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.011629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.016183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.016616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.017051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 9648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-21 03:06:15.040121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 03:06:15.040529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 9648 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "time: 16.6 s (started: 2021-12-21 03:05:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "train_df = pd.read_csv('task3_2021.training.csv')\n",
    "test_df = pd.read_csv('task3_2021.test.csv')\n",
    "n_pre_train_y = train_df['target']\n",
    "n_pre_train_x = train_df.drop(['target'], axis=1)\n",
    "n_pre_test_x = test_df\n",
    "# display(n_pre_train_x.head(), n_pre_train_y.head(), n_pre_train_y.nunique(), n_pre_test_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 126 ms (started: 2021-12-21 03:06:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def oh_pre(x):\n",
    "    for k in ['f15', 'f16', 'f17']:\n",
    "        tmp_one_hot_k =  pd.get_dummies(x[k], prefix=f\"{k}\")\n",
    "        x = pd.concat([x, tmp_one_hot_k],axis=1)\n",
    "        x = x.drop([k], axis=1)\n",
    "    return x\n",
    "\n",
    "oh_pre_train_x = oh_pre(n_pre_train_x)\n",
    "oh_pre_test_x = oh_pre(n_pre_test_x)\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(oh_pre_train_x)\n",
    "test_x = scaler.transform(oh_pre_test_x)\n",
    "\n",
    "ohenc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "train_y = ohenc.fit_transform(n_pre_train_y.values.reshape(-1,1))\n",
    "# mse = make_scorer(mean_squared_error, squared=False)nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2217 - accuracy: 0.1891 - val_loss: 1.9724 - val_accuracy: 0.2930 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.8156 - accuracy: 0.3121 - val_loss: 1.7059 - val_accuracy: 0.3560 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.6049 - accuracy: 0.3718 - val_loss: 1.5341 - val_accuracy: 0.3970 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.4545 - accuracy: 0.4254 - val_loss: 1.4033 - val_accuracy: 0.4400 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.3347 - accuracy: 0.4737 - val_loss: 1.2976 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.2337 - accuracy: 0.5194 - val_loss: 1.2065 - val_accuracy: 0.5390 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1501 - accuracy: 0.5666 - val_loss: 1.1304 - val_accuracy: 0.5700 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0775 - accuracy: 0.6041 - val_loss: 1.0621 - val_accuracy: 0.6010 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.0126 - accuracy: 0.6391 - val_loss: 1.0047 - val_accuracy: 0.6300 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.9565 - accuracy: 0.6706 - val_loss: 0.9495 - val_accuracy: 0.6550 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 0.6961 - val_loss: 0.9064 - val_accuracy: 0.6680 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.8598 - accuracy: 0.7172 - val_loss: 0.8634 - val_accuracy: 0.7130 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.8191 - accuracy: 0.7360 - val_loss: 0.8246 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.7511 - val_loss: 0.7919 - val_accuracy: 0.7350 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7664 - val_loss: 0.7598 - val_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.7794 - val_loss: 0.7308 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.7957 - val_loss: 0.7055 - val_accuracy: 0.7790 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.8064 - val_loss: 0.6821 - val_accuracy: 0.7840 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.8143 - val_loss: 0.6635 - val_accuracy: 0.7850 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.8262 - val_loss: 0.6378 - val_accuracy: 0.7940 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.8314 - val_loss: 0.6173 - val_accuracy: 0.8050 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.8397 - val_loss: 0.6002 - val_accuracy: 0.8030 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.8473 - val_loss: 0.5821 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.8512 - val_loss: 0.5629 - val_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8553 - val_loss: 0.5515 - val_accuracy: 0.8210 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8600 - val_loss: 0.5369 - val_accuracy: 0.8230 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8662 - val_loss: 0.5220 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.8697 - val_loss: 0.5089 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8750 - val_loss: 0.4977 - val_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8787 - val_loss: 0.4859 - val_accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8834 - val_loss: 0.4767 - val_accuracy: 0.8380 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8853 - val_loss: 0.4682 - val_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8893 - val_loss: 0.4543 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8936 - val_loss: 0.4456 - val_accuracy: 0.8540 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8951 - val_loss: 0.4359 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8986 - val_loss: 0.4320 - val_accuracy: 0.8480 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8976 - val_loss: 0.4244 - val_accuracy: 0.8430 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.9003 - val_loss: 0.4170 - val_accuracy: 0.8530 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.9040 - val_loss: 0.4035 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.9069 - val_loss: 0.3949 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.9051 - val_loss: 0.3944 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.9116 - val_loss: 0.3916 - val_accuracy: 0.8540 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.9109 - val_loss: 0.3842 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.9121 - val_loss: 0.3779 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.9141 - val_loss: 0.3727 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.9158 - val_loss: 0.3659 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.9159 - val_loss: 0.3579 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.9173 - val_loss: 0.3584 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.9192 - val_loss: 0.3545 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.9206 - val_loss: 0.3505 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.9197 - val_loss: 0.3435 - val_accuracy: 0.8670 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.9230 - val_loss: 0.3396 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.9243 - val_loss: 0.3386 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9218 - val_loss: 0.3298 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.9262 - val_loss: 0.3344 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.9253 - val_loss: 0.3239 - val_accuracy: 0.8730 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.9253 - val_loss: 0.3234 - val_accuracy: 0.8830 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.9282 - val_loss: 0.3179 - val_accuracy: 0.8790 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9278 - val_loss: 0.3220 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2566 - accuracy: 0.9281 - val_loss: 0.3111 - val_accuracy: 0.8760 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.9293 - val_loss: 0.3113 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9298 - val_loss: 0.3090 - val_accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9313 - val_loss: 0.3049 - val_accuracy: 0.8790 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9336 - val_loss: 0.3072 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9328 - val_loss: 0.2985 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9352 - val_loss: 0.2988 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9344 - val_loss: 0.2990 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9344 - val_loss: 0.2955 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9344 - val_loss: 0.2953 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9380 - val_loss: 0.2903 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9363 - val_loss: 0.2873 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9367 - val_loss: 0.2880 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9366 - val_loss: 0.2883 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9386 - val_loss: 0.2870 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9368 - val_loss: 0.2869 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.9384 - val_loss: 0.2838 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.9374 - val_loss: 0.2782 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9401 - val_loss: 0.2829 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9411 - val_loss: 0.2802 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9393 - val_loss: 0.2791 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9412 - val_loss: 0.2776 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9417 - val_loss: 0.2757 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9413 - val_loss: 0.2786 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9423 - val_loss: 0.2754 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9437 - val_loss: 0.2690 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9410 - val_loss: 0.2737 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9414 - val_loss: 0.2717 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.9453 - val_loss: 0.2742 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9428 - val_loss: 0.2702 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9450 - val_loss: 0.2690 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9444 - val_loss: 0.2657 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9433 - val_loss: 0.2669 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9440 - val_loss: 0.2665 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9460 - val_loss: 0.2647 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9449 - val_loss: 0.2645 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9466 - val_loss: 0.2668 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9472 - val_loss: 0.2637 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9463 - val_loss: 0.2600 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9464 - val_loss: 0.2617 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9469 - val_loss: 0.2626 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9480 - val_loss: 0.2623 - val_accuracy: 0.8970 - lr: 9.0484e-04\n",
      "Epoch 102/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9499 - val_loss: 0.2606 - val_accuracy: 0.9000 - lr: 8.1873e-04\n",
      "Epoch 103/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9502 - val_loss: 0.2598 - val_accuracy: 0.8980 - lr: 7.4082e-04\n",
      "Epoch 104/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9514 - val_loss: 0.2593 - val_accuracy: 0.9010 - lr: 6.7032e-04\n",
      "Epoch 105/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9507 - val_loss: 0.2578 - val_accuracy: 0.9030 - lr: 6.0653e-04\n",
      "Epoch 106/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9521 - val_loss: 0.2583 - val_accuracy: 0.8970 - lr: 5.4881e-04\n",
      "Epoch 107/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9539 - val_loss: 0.2578 - val_accuracy: 0.8990 - lr: 4.9659e-04\n",
      "Epoch 108/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9529 - val_loss: 0.2571 - val_accuracy: 0.9010 - lr: 4.4933e-04\n",
      "Epoch 109/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9540 - val_loss: 0.2582 - val_accuracy: 0.8990 - lr: 4.0657e-04\n",
      "Epoch 110/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9539 - val_loss: 0.2560 - val_accuracy: 0.9030 - lr: 3.6788e-04\n",
      "Epoch 111/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9542 - val_loss: 0.2569 - val_accuracy: 0.9000 - lr: 3.3287e-04\n",
      "Epoch 112/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9547 - val_loss: 0.2575 - val_accuracy: 0.9020 - lr: 3.0119e-04\n",
      "Epoch 113/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9559 - val_loss: 0.2567 - val_accuracy: 0.9000 - lr: 2.7253e-04\n",
      "Epoch 114/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9549 - val_loss: 0.2573 - val_accuracy: 0.8960 - lr: 2.4660e-04\n",
      "Epoch 115/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9560 - val_loss: 0.2569 - val_accuracy: 0.9000 - lr: 2.2313e-04\n",
      "Epoch 116/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9549 - val_loss: 0.2569 - val_accuracy: 0.9000 - lr: 2.0190e-04\n",
      "Epoch 117/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9554 - val_loss: 0.2557 - val_accuracy: 0.9020 - lr: 1.8268e-04\n",
      "Epoch 118/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9556 - val_loss: 0.2563 - val_accuracy: 0.9000 - lr: 1.6530e-04\n",
      "Epoch 119/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9558 - val_loss: 0.2562 - val_accuracy: 0.9020 - lr: 1.4957e-04\n",
      "Epoch 120/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9562 - val_loss: 0.2557 - val_accuracy: 0.9020 - lr: 1.3534e-04\n",
      "Epoch 121/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9557 - val_loss: 0.2558 - val_accuracy: 0.9000 - lr: 1.2246e-04\n",
      "Epoch 122/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9562 - val_loss: 0.2560 - val_accuracy: 0.9010 - lr: 1.1080e-04\n",
      "Epoch 123/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9566 - val_loss: 0.2559 - val_accuracy: 0.9010 - lr: 1.0026e-04\n",
      "Epoch 124/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9563 - val_loss: 0.2563 - val_accuracy: 0.9010 - lr: 9.0718e-05\n",
      "Epoch 125/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9570 - val_loss: 0.2559 - val_accuracy: 0.9010 - lr: 8.2085e-05\n",
      "Epoch 126/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9576 - val_loss: 0.2557 - val_accuracy: 0.9010 - lr: 7.4273e-05\n",
      "Epoch 127/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9556 - val_loss: 0.2557 - val_accuracy: 0.9000 - lr: 6.7205e-05\n",
      "Epoch 128/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9567 - val_loss: 0.2560 - val_accuracy: 0.9000 - lr: 6.0810e-05\n",
      "Epoch 129/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9561 - val_loss: 0.2560 - val_accuracy: 0.9000 - lr: 5.5023e-05\n",
      "Epoch 130/1000\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9571 - val_loss: 0.2557 - val_accuracy: 0.9000 - lr: 4.9787e-05\n",
      "Epoch 131/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9566 - val_loss: 0.2560 - val_accuracy: 0.9000 - lr: 4.5049e-05\n",
      "Epoch 132/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9562 - val_loss: 0.2557 - val_accuracy: 0.9000 - lr: 4.0762e-05\n",
      "Epoch 133/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9568 - val_loss: 0.2557 - val_accuracy: 0.9000 - lr: 3.6883e-05\n",
      "Epoch 134/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9570 - val_loss: 0.2558 - val_accuracy: 0.9000 - lr: 3.3373e-05\n",
      "Epoch 135/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9569 - val_loss: 0.2557 - val_accuracy: 0.9000 - lr: 3.0197e-05\n",
      "Epoch 136/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9566 - val_loss: 0.2557 - val_accuracy: 0.9000 - lr: 2.7324e-05\n",
      "Epoch 137/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9570 - val_loss: 0.2558 - val_accuracy: 0.9000 - lr: 2.4723e-05\n",
      "Model: \"dnn_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            multiple                  1680      \n",
      "                                                                 \n",
      " dense_13 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_14 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_15 (Dense)            multiple                  490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,170\n",
      "Trainable params: 2,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 1min 17s (started: 2021-12-21 03:21:11 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class DNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(DNN,self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.dense3 = tf.keras.layers.Dense(48, activation=tf.nn.relu)\n",
    "    self.output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    # x = self.dense2(x)\n",
    "    # x = self.dense3(x)\n",
    "    return self.output_layer(x)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-1e-1)\n",
    "\n",
    "\n",
    "callback_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 1000\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model = DNN()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[callback_lr,callback_early], verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 76.7 ms (started: 2021-12-21 03:29:41 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from pandas import RangeIndex\n",
    "\n",
    "nn_pred = model.predict(test_x)\n",
    "pred = np.where(nn_pred<0.5, 0, 1)\n",
    "output = ohenc.inverse_transform(pred)\n",
    "check = (output==None).sum()\n",
    "\n",
    "\n",
    "if check==0:\n",
    "    pd.Series(output.reshape(-1), index=RangeIndex(1, 2001), name='Predicted').to_csv('ans_nn_2.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
