{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7f8822-44ab-477b-87c0-1c3dac9dace3",
   "metadata": {},
   "source": [
    "# Boston House Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f63e25d-163d-4669-9e77-4e2b376d3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIM: per capita crime rate by town.\n",
    "#ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "#INDUS: proportion of nonretail business acres per town.\n",
    "#CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "#NOX: nitric oxides concentration (parts per 10 million).\n",
    "#RM: average number of rooms per dwelling.\n",
    "#AGE: proportion of owner-occupied units built prior to 1940.\n",
    "#DIS: weighted distances to five Boston employment centers.\n",
    "#RAD: index of accessibility to radial highways.\n",
    "#TAX: full-value property-tax rate per $10,000.\n",
    "#PTRATIO: pupil-teacher ratio by town.\n",
    "#B: 1000(Bk â€“ 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "#LSTAT: % lower status of the population.\n",
    "#MEDV: Median value of owner-occupied homes in $1000s.\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, DoubleType\n",
    "\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"CRIM\",DoubleType(),True) \\\n",
    "      .add(\"ZN\",DoubleType(),True) \\\n",
    "      .add(\"INDUS\",DoubleType(),True) \\\n",
    "      .add(\"CHAS\",DoubleType(),True) \\\n",
    "      .add(\"NOX\",DoubleType(),True) \\\n",
    "      .add(\"RM\",DoubleType(),True) \\\n",
    "      .add(\"AGE\",DoubleType(),True) \\\n",
    "      .add(\"DIS\",DoubleType(),True) \\\n",
    "      .add(\"RAD\",DoubleType(),True) \\\n",
    "      .add(\"TAX\",DoubleType(),True)\\\n",
    "      .add(\"PTRATIO\",DoubleType(),True)\\\n",
    "      .add(\"B\",DoubleType(),True)\\\n",
    "      .add(\"LSTAT\",DoubleType(),True)\\\n",
    "      .add(\"MEDV\",DoubleType(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53e5b67-93a4-4c8b-95ae-7a9615d6a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|  TAX|PTRATIO|     B|LSTAT|MEDV|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31| 0.0|0.538|6.575| 65.2|  4.09|1.0|296.0|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07| 0.0|0.469|6.421| 78.9|4.9671|2.0|242.0|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07| 0.0|0.469|7.185| 61.1|4.9671|2.0|242.0|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18| 0.0|0.458|6.998| 45.8|6.0622|3.0|222.0|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18| 0.0|0.458|7.147| 54.2|6.0622|3.0|222.0|   18.7| 396.9| 5.33|36.2|\n",
      "|0.02985| 0.0| 2.18| 0.0|0.458| 6.43| 58.7|6.0622|3.0|222.0|   18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87| 0.0|0.524|6.012| 66.6|5.5605|5.0|311.0|   15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87| 0.0|0.524|6.172| 96.1|5.9505|5.0|311.0|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87| 0.0|0.524|5.631|100.0|6.0821|5.0|311.0|   15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87| 0.0|0.524|6.004| 85.9|6.5921|5.0|311.0|   15.2|386.71| 17.1|18.9|\n",
      "|0.22489|12.5| 7.87| 0.0|0.524|6.377| 94.3|6.3467|5.0|311.0|   15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5| 7.87| 0.0|0.524|6.009| 82.9|6.2267|5.0|311.0|   15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5| 7.87| 0.0|0.524|5.889| 39.0|5.4509|5.0|311.0|   15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0| 8.14| 0.0|0.538|5.949| 61.8|4.7075|4.0|307.0|   21.0| 396.9| 8.26|20.4|\n",
      "|0.63796| 0.0| 8.14| 0.0|0.538|6.096| 84.5|4.4619|4.0|307.0|   21.0|380.02|10.26|18.2|\n",
      "|0.62739| 0.0| 8.14| 0.0|0.538|5.834| 56.5|4.4986|4.0|307.0|   21.0|395.62| 8.47|19.9|\n",
      "|1.05393| 0.0| 8.14| 0.0|0.538|5.935| 29.3|4.4986|4.0|307.0|   21.0|386.85| 6.58|23.1|\n",
      "| 0.7842| 0.0| 8.14| 0.0|0.538| 5.99| 81.7|4.2579|4.0|307.0|   21.0|386.75|14.67|17.5|\n",
      "|0.80271| 0.0| 8.14| 0.0|0.538|5.456| 36.6|3.7965|4.0|307.0|   21.0|288.99|11.69|20.2|\n",
      "| 0.7258| 0.0| 8.14| 0.0|0.538|5.727| 69.5|3.7965|4.0|307.0|   21.0|390.95|11.28|18.2|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "boston_housing= spark.read.csv('data/boston_housing.csv', sep=',',header=False, schema = schema)\n",
    "boston_housing = boston_housing.dropna()\n",
    "boston_housing.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af28080-868a-46a6-9804-f0fa4ef7520b",
   "metadata": {},
   "source": [
    "### Summarize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb39086-ef48-4444-8176-d56bf4d7a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|              CRIM|                ZN|               AGE|              MEDV|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|               452|               452|               452|               452|\n",
      "|   mean|1.4208250442477868|12.721238938053098| 65.55796460176992|23.750442477876135|\n",
      "| stddev|2.4958943920051566| 24.32603179418856|28.127025034855407| 8.808601660786652|\n",
      "|    min|           0.00632|               0.0|               2.9|               6.3|\n",
      "|    25%|           0.06911|               0.0|              40.5|              18.5|\n",
      "|    50%|           0.19073|               0.0|              71.7|              21.9|\n",
      "|    75%|           1.20742|              20.0|              91.6|              26.6|\n",
      "|    max|           9.96654|             100.0|             100.0|              50.0|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "boston_housing.select('CRIM', 'ZN','AGE', 'MEDV').summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5716d2-cf5d-4275-9880-f43a2dfb654d",
   "metadata": {},
   "source": [
    "### Create an assembler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3384f5f-7dc2-4264-9fd7-c5f1a3463aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/30 21:00:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+----+\n",
      "|features                                                                 |MEDV|\n",
      "+-------------------------------------------------------------------------+----+\n",
      "|[0.00632,18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98]  |24.0|\n",
      "|[0.02731,0.0,7.07,0.0,0.469,6.421,78.9,4.9671,2.0,242.0,17.8,396.9,9.14] |21.6|\n",
      "|[0.02729,0.0,7.07,0.0,0.469,7.185,61.1,4.9671,2.0,242.0,17.8,392.83,4.03]|34.7|\n",
      "|[0.03237,0.0,2.18,0.0,0.458,6.998,45.8,6.0622,3.0,222.0,18.7,394.63,2.94]|33.4|\n",
      "|[0.06905,0.0,2.18,0.0,0.458,7.147,54.2,6.0622,3.0,222.0,18.7,396.9,5.33] |36.2|\n",
      "+-------------------------------------------------------------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import the necessary class\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'\n",
    "], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "boston_assembled = assembler.transform(boston_housing)\n",
    "\n",
    "# Check the resulting column\n",
    "boston_assembled.select('features', 'MEDV').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d12ca-0982-4dfb-a6c3-953104ab7a13",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c9053a-0b0b-470a-8c37-beea34c20251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853982300884956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "boston_train, boston_test = boston_assembled.randomSplit([0.8, 0.2], seed=17)\n",
    "\n",
    "# Check that training set has around 80% of records\n",
    "training_ratio = boston_train.count() / boston_housing.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4345fd8-8022-4f41-8d8a-354c89d7d9bd",
   "metadata": {},
   "source": [
    "### Train linear regression model and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b92582d-23fc-4fc8-8100-b421ff3735bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/30 21:00:29 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|MEDV|prediction        |\n",
      "+----+------------------+\n",
      "|24.0|30.254391159626515|\n",
      "|50.0|39.95712392178673 |\n",
      "|44.0|36.31241607566815 |\n",
      "|31.1|31.58506633539052 |\n",
      "|16.5|24.1436147841959  |\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.000236529534943"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='MEDV',regParam=0.3).fit(boston_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "predictions = regression.transform(boston_test)\n",
    "predictions.select('MEDV', 'prediction').show(5, False)\n",
    "\n",
    "# Calculate the RMSE\n",
    "RegressionEvaluator(labelCol='MEDV').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8943e7c-bcb9-4f90-a946-bac7023f8c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
