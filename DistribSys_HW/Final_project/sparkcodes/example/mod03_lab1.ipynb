{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.types import StringType,DoubleType,IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySparkShell'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load csv Dataset \n",
    "df=spark.read.csv('data/sample_data.csv',inferSchema=True,header=True)\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratings', 'age', 'experience', 'family', 'mobile']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns of dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of columns\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of records in dataframe\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataset\n",
    "df.count(),len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ratings: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: double (nullable = true)\n",
      " |-- family: integer (nullable = true)\n",
      " |-- mobile: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print dataframe schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+\n",
      "|ratings|age|experience|family| mobile|\n",
      "+-------+---+----------+------+-------+\n",
      "|      3| 32|       9.0|     3|   Vivo|\n",
      "|      3| 27|      13.0|     3|  Apple|\n",
      "|      4| 22|       2.5|     0|Samsung|\n",
      "|      4| 37|      16.5|     4|  Apple|\n",
      "|      5| 27|       9.0|     1|     MI|\n",
      "|      4| 27|       9.0|     0|   Oppo|\n",
      "|      5| 37|      23.0|     5|   Vivo|\n",
      "|      5| 37|      23.0|     5|Samsung|\n",
      "|      3| 22|       2.5|     0|  Apple|\n",
      "|      3| 27|       6.0|     0|     MI|\n",
      "|      2| 27|       6.0|     2|   Oppo|\n",
      "|      5| 27|       6.0|     2|Samsung|\n",
      "|      3| 37|      16.5|     5|  Apple|\n",
      "|      5| 27|       6.0|     0|     MI|\n",
      "|      4| 22|       6.0|     1|   Oppo|\n",
      "|      4| 37|       9.0|     2|Samsung|\n",
      "|      4| 27|       6.0|     1|  Apple|\n",
      "|      1| 37|      23.0|     5|     MI|\n",
      "|      2| 42|      23.0|     2|   Oppo|\n",
      "|      4| 37|       6.0|     0|   Vivo|\n",
      "+-------+---+----------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# display fisrt few rows of dataframe\n",
    "df.show()\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(ratings=3, age=32, experience=9.0, family=3, mobile='Vivo'),\n",
       " Row(ratings=3, age=27, experience=13.0, family=3, mobile='Apple'),\n",
       " Row(ratings=4, age=22, experience=2.5, family=0, mobile='Samsung'),\n",
       " Row(ratings=4, age=37, experience=16.5, family=4, mobile='Apple'),\n",
       " Row(ratings=5, age=27, experience=9.0, family=1, mobile='MI')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display fisrt 5 rows of dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ratings=2, age=32, experience=16.5, family=2, mobile='Oppo'),\n",
       " Row(ratings=3, age=27, experience=6.0, family=0, mobile='MI'),\n",
       " Row(ratings=3, age=27, experience=6.0, family=0, mobile='MI'),\n",
       " Row(ratings=4, age=22, experience=6.0, family=1, mobile='Oppo'),\n",
       " Row(ratings=4, age=37, experience=6.0, family=0, mobile='Vivo')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display last 5 rows of dataframe\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ratings=3, age=32, experience=9.0, family=3, mobile='Vivo')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display first row of dataframe\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+\n",
      "|ratings|age|experience|family| mobile|\n",
      "+-------+---+----------+------+-------+\n",
      "|      3| 32|       9.0|     3|   Vivo|\n",
      "|      3| 27|      13.0|     3|  Apple|\n",
      "|      4| 22|       2.5|     0|Samsung|\n",
      "+-------+---+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select * from dfTable limit 3''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------+\n",
      "|summary|           ratings|               age|        experience|            family|mobile|\n",
      "+-------+------------------+------------------+------------------+------------------+------+\n",
      "|  count|                33|                33|                33|                33|    33|\n",
      "|   mean|3.5757575757575757|30.484848484848484|10.303030303030303|1.8181818181818181|  null|\n",
      "| stddev|1.1188806636071336|  6.18527087180309| 6.770731351213326|1.8448330794164254|  null|\n",
      "|    min|                 1|                22|               2.5|                 0| Apple|\n",
      "|    max|                 5|                42|              23.0|                 5|  Vivo|\n",
      "+-------+------------------+------------------+------------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# info about dataframe\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------+\n",
      "|summary|           ratings|               age|        experience|            family|mobile|\n",
      "+-------+------------------+------------------+------------------+------------------+------+\n",
      "|  count|                33|                33|                33|                33|    33|\n",
      "|   mean|3.5757575757575757|30.484848484848484|10.303030303030303|1.8181818181818181|  null|\n",
      "| stddev|1.1188806636071336|  6.18527087180309| 6.770731351213326|1.8448330794164254|  null|\n",
      "|    min|                 1|                22|               2.5|                 0| Apple|\n",
      "|    25%|                 3|                27|               6.0|                 0|  null|\n",
      "|    50%|                 4|                27|               6.0|                 1|  null|\n",
      "|    75%|                 4|                37|              16.5|                 3|  null|\n",
      "|    max|                 5|                42|              23.0|                 5|  Vivo|\n",
      "+-------+------------------+------------------+------------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# info about dataframe\n",
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age| mobile|\n",
      "+---+-------+\n",
      "| 32|   Vivo|\n",
      "| 27|  Apple|\n",
      "| 22|Samsung|\n",
      "| 37|  Apple|\n",
      "| 27|     MI|\n",
      "+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select only 2 columns\n",
    "df.select('age','mobile').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age| mobile|\n",
      "+---+-------+\n",
      "| 32|   Vivo|\n",
      "| 27|  Apple|\n",
      "| 22|Samsung|\n",
      "| 37|  Apple|\n",
      "| 27|     MI|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "spark.sql('select age, mobile from dfTable limit 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|ratings|family| mobile|\n",
      "+-------+------+-------+\n",
      "|      3|     3|   Vivo|\n",
      "|      3|     3|  Apple|\n",
      "|      4|     0|Samsung|\n",
      "+-------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# use different pyspark sql functions\n",
    "df.select(\n",
    "    fn.expr('ratings'), \n",
    "    fn.col('family'), \n",
    "    fn.column('mobile'))\\\n",
    ".show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|age1|\n",
      "+----+\n",
      "|  33|\n",
      "|  28|\n",
      "|  23|\n",
      "|  38|\n",
      "|  28|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(fn.expr('age+1 AS age1')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|age1|\n",
      "+----+\n",
      "|  33|\n",
      "|  28|\n",
      "|  23|\n",
      "|  38|\n",
      "|  28|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('age+1 AS age1').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+------+\n",
      "|ratings|age|experience|family| mobile|over30|\n",
      "+-------+---+----------+------+-------+------+\n",
      "|      3| 32|       9.0|     3|   Vivo|  true|\n",
      "|      3| 27|      13.0|     3|  Apple| false|\n",
      "|      4| 22|       2.5|     0|Samsung| false|\n",
      "|      4| 37|      16.5|     4|  Apple|  true|\n",
      "|      5| 27|       9.0|     1|     MI| false|\n",
      "+-------+---+----------+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\n",
    "'*',  # all original columns\n",
    "'(age>=30) as over30')\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+------+\n",
      "|ratings|age|experience|family| mobile|over30|\n",
      "+-------+---+----------+------+-------+------+\n",
      "|      3| 32|       9.0|     3|   Vivo|  true|\n",
      "|      3| 27|      13.0|     3|  Apple| false|\n",
      "|      4| 22|       2.5|     0|Samsung| false|\n",
      "|      4| 37|      16.5|     4|  Apple|  true|\n",
      "|      5| 27|       9.0|     1|     MI| false|\n",
      "+-------+---+----------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT *, (age>=30) as over30 FROM dfTable LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+----------------+\n",
      "|ratings|age|experience|family|mobile |age_after_10_yrs|\n",
      "+-------+---+----------+------+-------+----------------+\n",
      "|3      |32 |9.0       |3     |Vivo   |42              |\n",
      "|3      |27 |13.0      |3     |Apple  |37              |\n",
      "|4      |22 |2.5       |0     |Samsung|32              |\n",
      "|4      |37 |16.5      |4     |Apple  |47              |\n",
      "|5      |27 |9.0       |1     |MI     |37              |\n",
      "|4      |27 |9.0       |0     |Oppo   |37              |\n",
      "|5      |37 |23.0      |5     |Vivo   |47              |\n",
      "|5      |37 |23.0      |5     |Samsung|47              |\n",
      "|3      |22 |2.5       |0     |Apple  |32              |\n",
      "|3      |27 |6.0       |0     |MI     |37              |\n",
      "+-------+---+----------+------+-------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with column\n",
    "df.withColumn('age_after_10_yrs',(df['age']+10)).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+----------+\n",
      "|ratings|age|experience|family|mobile |age_double|\n",
      "+-------+---+----------+------+-------+----------+\n",
      "|3      |32 |9.0       |3     |Vivo   |32.0      |\n",
      "|3      |27 |13.0      |3     |Apple  |27.0      |\n",
      "|4      |22 |2.5       |0     |Samsung|22.0      |\n",
      "|4      |37 |16.5      |4     |Apple  |37.0      |\n",
      "|5      |27 |9.0       |1     |MI     |27.0      |\n",
      "|4      |27 |9.0       |0     |Oppo   |27.0      |\n",
      "|5      |37 |23.0      |5     |Vivo   |37.0      |\n",
      "|5      |37 |23.0      |5     |Samsung|37.0      |\n",
      "|3      |22 |2.5       |0     |Apple  |22.0      |\n",
      "|3      |27 |6.0       |0     |MI     |27.0      |\n",
      "+-------+---+----------+------+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert data type\n",
    "df.withColumn('age_double',df['age'].cast(DoubleType())).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+----------+\n",
      "|ratings|age|experience|family| mobile|age_double|\n",
      "+-------+---+----------+------+-------+----------+\n",
      "|      3| 32|       9.0|     3|   Vivo|      32.0|\n",
      "|      3| 27|      13.0|     3|  Apple|      27.0|\n",
      "|      4| 22|       2.5|     0|Samsung|      22.0|\n",
      "|      4| 37|      16.5|     4|  Apple|      37.0|\n",
      "|      5| 27|       9.0|     1|     MI|      27.0|\n",
      "+-------+---+----------+------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use selectExpr method\n",
    "df.selectExpr(\n",
    "'*',  # all original columns\n",
    "'cast(age as double) as age_double')\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|ratings|age|experience|family|\n",
      "+-------+---+----------+------+\n",
      "|      3| 32|       9.0|     3|\n",
      "|      3| 27|      13.0|     3|\n",
      "|      4| 22|       2.5|     0|\n",
      "|      4| 37|      16.5|     4|\n",
      "|      5| 27|       9.0|     1|\n",
      "+-------+---+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete a column\n",
    "df_new=df.drop('mobile')\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|ratings|experience|family|\n",
      "+-------+----------+------+\n",
      "|      3|       9.0|     3|\n",
      "|      3|      13.0|     3|\n",
      "|      4|       2.5|     0|\n",
      "|      4|      16.5|     4|\n",
      "|      5|       9.0|     1|\n",
      "+-------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new=df.drop('age', 'mobile')\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+------+\n",
      "|ratings|age|experience|family|mobile|\n",
      "+-------+---+----------+------+------+\n",
      "|      3| 32|       9.0|     3|  Vivo|\n",
      "|      5| 37|      23.0|     5|  Vivo|\n",
      "|      4| 37|       6.0|     0|  Vivo|\n",
      "|      5| 37|      13.0|     1|  Vivo|\n",
      "|      4| 37|       6.0|     0|  Vivo|\n",
      "+-------+---+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the records \n",
    "df.filter(df['mobile']=='Vivo').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "|age|ratings|mobile|\n",
      "+---+-------+------+\n",
      "| 32|      3|  Vivo|\n",
      "| 37|      5|  Vivo|\n",
      "| 37|      4|  Vivo|\n",
      "| 37|      5|  Vivo|\n",
      "| 37|      4|  Vivo|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the records \n",
    "df.filter(df['mobile']=='Vivo').select('age','ratings','mobile').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "|age|ratings|mobile|\n",
      "+---+-------+------+\n",
      "| 32|      3|  Vivo|\n",
      "| 37|      5|  Vivo|\n",
      "| 37|      4|  Vivo|\n",
      "| 37|      5|  Vivo|\n",
      "| 37|      4|  Vivo|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the records \n",
    "df.filter(\"mobile=='Vivo'\").select('age','ratings','mobile').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "|age|ratings|mobile|\n",
      "+---+-------+------+\n",
      "| 32|      3|  Vivo|\n",
      "| 37|      5|  Vivo|\n",
      "| 37|      4|  Vivo|\n",
      "| 37|      5|  Vivo|\n",
      "| 37|      4|  Vivo|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the records with spark sql \n",
    "spark.sql(\"\"\"select age, ratings, mobile from dfTable where mobile=='Vivo'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+------+\n",
      "|ratings|age|experience|family|mobile|\n",
      "+-------+---+----------+------+------+\n",
      "|      5| 37|      23.0|     5|  Vivo|\n",
      "|      5| 37|      13.0|     1|  Vivo|\n",
      "+-------+---+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the multiple conditions\n",
    "df.filter(df['mobile']=='Vivo').filter(df['experience'] >10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+------+\n",
      "|ratings|age|experience|family|mobile|\n",
      "+-------+---+----------+------+------+\n",
      "|      5| 37|      23.0|     5|  Vivo|\n",
      "|      5| 37|      13.0|     1|  Vivo|\n",
      "+-------+---+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the multiple conditions\n",
    "df.filter((df['mobile']=='Vivo')&(df['experience'] >10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+------+\n",
      "|ratings|age|experience|family|mobile|\n",
      "+-------+---+----------+------+------+\n",
      "|      5| 37|      23.0|     5|  Vivo|\n",
      "|      5| 37|      13.0|     1|  Vivo|\n",
      "+-------+---+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the multiple conditions\n",
    "df.filter(\"mobile=='Vivo' and experience>10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+------+\n",
      "|ratings|age|experience|family|mobile|\n",
      "+-------+---+----------+------+------+\n",
      "|      5| 37|      23.0|     5|  Vivo|\n",
      "|      5| 37|      13.0|     1|  Vivo|\n",
      "+-------+---+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the records with spark sql \n",
    "spark.sql('''select * from dfTable where mobile=='Vivo' and experience>10''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinct Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| mobile|\n",
      "+-------+\n",
      "|     MI|\n",
      "|   Oppo|\n",
      "|Samsung|\n",
      "|   Vivo|\n",
      "|  Apple|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distinct Values in a column\n",
    "df.select('mobile').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|ratings| mobile|\n",
      "+-------+-------+\n",
      "|      5|Samsung|\n",
      "|      5|     MI|\n",
      "|      4|  Apple|\n",
      "|      3|  Apple|\n",
      "|      2|   Oppo|\n",
      "|      4|   Oppo|\n",
      "|      1|     MI|\n",
      "|      3|     MI|\n",
      "|      4|Samsung|\n",
      "|      5|   Vivo|\n",
      "|      4|   Vivo|\n",
      "|      3|   Vivo|\n",
      "|      2|Samsung|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distinct Values in columns\n",
    "df.select('ratings', 'mobile').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distinct value count\n",
    "df.select('mobile').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| mobile|\n",
      "+-------+\n",
      "|     MI|\n",
      "|   Oppo|\n",
      "|Samsung|\n",
      "|   Vivo|\n",
      "|  Apple|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "spark.sql('''select distinct(mobile) from dfTable''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|counts|\n",
      "+------+\n",
      "|     5|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "spark.sql('''select count(distinct(mobile)) as counts from dfTable''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+\n",
      "|ratings|age|experience|family| mobile|\n",
      "+-------+---+----------+------+-------+\n",
      "|      4| 22|       6.0|     1|   Oppo|\n",
      "|      4| 22|       2.5|     0|Samsung|\n",
      "|      5| 22|       2.5|     0|Samsung|\n",
      "|      3| 22|       2.5|     0|  Apple|\n",
      "|      4| 22|       6.0|     1|   Oppo|\n",
      "|      5| 27|       6.0|     0|     MI|\n",
      "|      5| 27|       6.0|     2|Samsung|\n",
      "|      5| 27|       9.0|     1|     MI|\n",
      "|      4| 27|       6.0|     1|  Apple|\n",
      "|      3| 27|      13.0|     3|  Apple|\n",
      "+-------+---+----------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort age\n",
    "df.sort('age').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+\n",
      "|ratings|age|experience|family| mobile|\n",
      "+-------+---+----------+------+-------+\n",
      "|      1| 37|      23.0|     5|     MI|\n",
      "|      2| 27|       6.0|     2|   Oppo|\n",
      "|      2| 32|      16.5|     2|   Oppo|\n",
      "|      2| 42|      23.0|     2|   Oppo|\n",
      "|      2| 27|       9.0|     2|Samsung|\n",
      "|      2| 27|       6.0|     2|   Oppo|\n",
      "|      3| 22|       2.5|     0|  Apple|\n",
      "|      3| 27|       6.0|     0|     MI|\n",
      "|      3| 27|       6.0|     0|     MI|\n",
      "|      3| 27|       6.0|     0|     MI|\n",
      "+-------+---+----------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# order by ratings and family\n",
    "df.orderBy('ratings', 'family').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+\n",
      "|ratings|age|experience|family| mobile|\n",
      "+-------+---+----------+------+-------+\n",
      "|      5| 37|      23.0|     5|   Vivo|\n",
      "|      5| 37|      23.0|     5|Samsung|\n",
      "|      1| 37|      23.0|     5|     MI|\n",
      "|      3| 42|      23.0|     5|     MI|\n",
      "|      2| 42|      23.0|     2|   Oppo|\n",
      "|      3| 37|      16.5|     5|  Apple|\n",
      "|      2| 32|      16.5|     2|   Oppo|\n",
      "|      4| 37|      16.5|     4|  Apple|\n",
      "|      3| 37|      16.5|     5|  Apple|\n",
      "|      3| 27|      13.0|     3|  Apple|\n",
      "+-------+---+----------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# descending order\n",
    "df.orderBy('experience', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------+\n",
      "|ratings|age| mobile|\n",
      "+-------+---+-------+\n",
      "|      2| 42|   Oppo|\n",
      "|      3| 42|     MI|\n",
      "|      4| 37|  Apple|\n",
      "|      5| 37|   Vivo|\n",
      "|      3| 37|  Apple|\n",
      "|      1| 37|     MI|\n",
      "|      5| 37|Samsung|\n",
      "|      4| 37|Samsung|\n",
      "|      4| 37|   Vivo|\n",
      "|      3| 37|  Apple|\n",
      "+-------+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "spark.sql(\"\"\"select ratings, age, mobile from dfTable \n",
    "        order by age desc\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "| name| age|weight|\n",
      "+-----+----+------+\n",
      "|Alice|  22|    52|\n",
      "| John|null|    68|\n",
      "| Mary|  24|    55|\n",
      "| Alan|null|  null|\n",
      "| Jane|  32|    48|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "data = [('Alice', 22, 52),\n",
    "        ('John', None , 68),\n",
    "        ('Mary', 24, 55),\n",
    "        ('Alan', None, None),\n",
    "        ('Jane', 32, 48)]\n",
    "\n",
    "emp=spark.createDataFrame(data, ['name', 'age', 'weight'])\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|weight|\n",
      "+-----+---+------+\n",
      "|Alice| 22|    52|\n",
      "| John|  1|    68|\n",
      "| Mary| 24|    55|\n",
      "| Alan|  1|     1|\n",
      "| Jane| 32|    48|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill null value\n",
    "emp.fillna(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|weight|\n",
      "+-----+---+------+\n",
      "|Alice| 22|    52|\n",
      "| John| 30|    68|\n",
      "| Mary| 24|    55|\n",
      "| Alan| 30|    50|\n",
      "| Jane| 32|    48|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill null value\n",
    "val={'age': 30, 'weight': 50}\n",
    "emp.fillna(val).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|weight|\n",
      "+-----+---+------+\n",
      "|Alice| 22|    52|\n",
      "| Mary| 24|    55|\n",
      "| Jane| 32|    48|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop null data\n",
    "emp.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "| name| age|weight|\n",
      "+-----+----+------+\n",
      "|Alice|  22|    52|\n",
      "| John|null|    68|\n",
      "| Mary|  24|    55|\n",
      "| Jane|  32|    48|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop null data\n",
    "emp.dropna(thresh=2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| name|age|country|\n",
      "+-----+---+-------+\n",
      "|Alice| 22|    USA|\n",
      "| John| 18|  Japan|\n",
      "| Mary| 24|Germany|\n",
      "|Alice| 22|    USA|\n",
      "| Jane| 24|Germany|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "data = [('Alice', 22, 'USA'),\n",
    "        ('John', 18 , 'Japan'),\n",
    "        ('Mary', 24, 'Germany'),\n",
    "        ('Alice', 22, 'USA'),\n",
    "        ('Jane', 24, 'Germany')]\n",
    "\n",
    "cust=spark.createDataFrame(data, ['name', 'age', 'country'])\n",
    "cust.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| name|age|country|\n",
      "+-----+---+-------+\n",
      "| Jane| 24|Germany|\n",
      "|Alice| 22|    USA|\n",
      "| Mary| 24|Germany|\n",
      "| John| 18|  Japan|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate rows\n",
    "cust.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| name|age|country|\n",
      "+-----+---+-------+\n",
      "| John| 18|  Japan|\n",
      "|Alice| 22|    USA|\n",
      "| Mary| 24|Germany|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate rows base on some columns\n",
    "cust.dropDuplicates(subset=['age', 'country']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| name|age|country|\n",
      "+-----+---+-------+\n",
      "| John| 18|  Japan|\n",
      "|Alice| 22|    USA|\n",
      "| Mary| 24|Germany|\n",
      "| Jane| 24|Germany|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 15:48:50 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "22/05/25 15:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:919)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:154)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:262)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:169)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/05/25 15:48:50 ERROR TaskSchedulerImpl: Lost executor 5 on 172.17.0.2: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/05/25 15:48:50 ERROR TaskSchedulerImpl: Lost executor 1 on 172.17.0.2: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/05/25 15:48:50 ERROR TaskSchedulerImpl: Lost executor 0 on 172.17.0.2: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/05/25 15:48:50 ERROR TaskSchedulerImpl: Lost executor 3 on 172.17.0.2: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "cust.createOrReplaceTempView(\"custTable\")\n",
    "spark.sql('''select distinct * from custTable''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
